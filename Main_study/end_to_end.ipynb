{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug the end-to-end optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import qmc\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error,root_mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV,KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, MultiTaskElasticNetCV\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pyswarms as ps\n",
    "\n",
    "from jax import grad\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,TensorDataset,Subset\n",
    "\n",
    "import optuna\n",
    "import random\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructed padded numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cells = pd.read_csv(\"../Data_preprocessing/training.csv\",header=None).to_numpy(dtype=str).reshape(-1,).tolist()\n",
    "test_in_cells = pd.read_csv(\"../Data_preprocessing/test_in.csv\",header=None).to_numpy(dtype=str).reshape(-1,).tolist()\n",
    "test_out_cells = pd.read_csv(\"../Data_preprocessing/test_out.csv\",header=None).to_numpy(dtype=str).reshape(-1,).tolist()\n",
    "\n",
    "num_training_cells = len(training_cells)\n",
    "num_test_in_cells = len(test_in_cells)\n",
    "num_test_out_cells = len(test_out_cells)\n",
    "\n",
    "a = np.loadtxt('../Empirical_model_fitting/Empirical_parameters_global_train_py.csv').item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_PCA = np.loadtxt(\"Processed_input_output/X_train_PCA.csv\",delimiter=\",\")\n",
    "X_test_in_PCA = np.loadtxt(\"Processed_input_output/X_test_in_PCA.csv\",delimiter=\",\")\n",
    "X_test_out_PCA = np.loadtxt(\"Processed_input_output/X_test_out_PCA.csv\",delimiter=\",\")\n",
    "\n",
    "N_train = np.loadtxt(\"Processed_input_output/N_train.csv\",delimiter=\",\")\n",
    "N_test_in = np.loadtxt(\"Processed_input_output/N_test_in.csv\",delimiter=\",\")\n",
    "N_test_out = np.loadtxt(\"Processed_input_output/N_test_out.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and transform feature using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add intercept for end-to-end loss\n",
    "X_train_PCA_1 = np.concatenate((np.ones((len(X_train_PCA),1)),X_train_PCA),axis=1)\n",
    "X_test_in_PCA_1 = np.concatenate((np.ones((len(X_test_in_PCA),1)),X_test_in_PCA),axis=1)\n",
    "X_test_out_PCA_1 = np.concatenate((np.ones((len(X_test_out_PCA),1)),X_test_out_PCA),axis=1)\n",
    "\n",
    "Q_train = np.array([np.linspace(1,0.8,21)] * num_training_cells)\n",
    "Q_test_in = np.array([np.linspace(1,0.8,21)] * num_test_in_cells)\n",
    "Q_test_out = np.array([np.linspace(1,0.8,21)] * num_test_out_cells)\n",
    "\n",
    "num_features = 10\n",
    "param_bnd=(-10,10)\n",
    "num_features_1 = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the empirical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_model(global_p,b1,b2,b3,N_eq,b_weight=[1e-3,1e2,1e2]):\n",
    "    a1 = global_p\n",
    "    # Match the scaling for end-to-end formulation\n",
    "    return 1 - b1*N_eq**a1*b_weight[0] - 1/(1+np.exp((b2*b_weight[1]-N_eq)/(b3*b_weight[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end elastic net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define end-to-end objective function and empirical models for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two global power terms, four cell specific parameters.\n",
    "def end_to_end_loss(W_,X,N,Q,a,alpha,rho): \n",
    "    # Without constraining the absolute values and add scaling for each X*wi\n",
    "    n_features = X.shape[1]\n",
    "    W = W_.reshape(n_features,3)\n",
    "    len_interp = Q.shape[1]\n",
    "    I_nm = np.ones_like(Q)\n",
    "    I_1m = np.ones((1,len_interp))\n",
    "\n",
    "    w1 = W[:,0].reshape(-1,1)\n",
    "    w2 = W[:,1].reshape(-1,1)\n",
    "    w3 = W[:,2].reshape(-1,1)\n",
    "\n",
    "    # Terms inside the norm\n",
    "    term_2 = X@w1@I_1m*1e-3 *  N**a\n",
    "    term_3 = I_nm /( I_nm + np.exp(  (X@w2@I_1m*1e2 -N) / (X@w3@I_1m*1e2 ) ))\n",
    "\n",
    "    loss_1 = np.mean(np.nanmean(np.array(I_nm - term_2 - term_3 - Q )**2,axis=1))\n",
    "    loss_2 = np.sum(W[3:] ** 2) * 0.5 # L2 norm\n",
    "    loss_3 = np.sum(np.abs(W[3:])) # L1 norm\n",
    "    loss = loss_1 * 100 + alpha*(rho*loss_3 + (1-rho)*loss_2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define nonlinear constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define three nonlinear constraints to ensure b1, b2, b3 are all positive\n",
    "def g1(W_,X_):\n",
    "    n_features = X_.shape[1]\n",
    "    W = W_.reshape(n_features,3)\n",
    "    w1 = W[:,0].reshape(-1,1)    \n",
    "    \n",
    "    X = np.mat(X_)\n",
    "    # Terms inside the norm\n",
    "    b1 = X*w1*1e-3\n",
    "    return np.min(b1)\n",
    "\n",
    "def g2(W_,X_):\n",
    "    n_features = X_.shape[1]\n",
    "    W = W_.reshape(n_features,3)\n",
    "    X = np.mat(X_)\n",
    "    w2 = W[:,1].reshape(-1,1)\n",
    "    # Terms inside the norm\n",
    "    b2 = X*w2*1e2\n",
    "    return np.min(b2)\n",
    "\n",
    "def g3(W_,X_):\n",
    "    n_features = X_.shape[1]\n",
    "    W = W_.reshape(n_features,3)\n",
    "    X = np.mat(X_)\n",
    "    w3 = W[:,2].reshape(-1,1)\n",
    "    # Terms inside the norm\n",
    "    b3 = X*w3*1e2\n",
    "    return np.min(b3)\n",
    "\n",
    "def visualize_opt_res(results):\n",
    "    best_result = min(results, key=lambda x: x.fun)\n",
    "    print(f\"best MSE: {best_result.fun}\")\n",
    "    print(f\"best W: {best_result.x}\")\n",
    "\n",
    "    obj_fun_values = [result.fun for result in results]\n",
    "    s_or_f = np.array([result.success for result in results],dtype=int)\n",
    "    fig,ax = plt.subplots(1,2,figsize=(6,2.5),dpi=100)\n",
    "    ax[0].hist(obj_fun_values,bins=20, color='cornflowerblue', edgecolor='black')\n",
    "    ax[0].set_xlabel('Objective function value')\n",
    "    ax[0].set_ylabel('Frequency')\n",
    "\n",
    "    ax[1].hist(s_or_f,color='cornflowerblue', edgecolor='black')\n",
    "    ax[1].set_xlabel('Success/fail')\n",
    "    ax[1].set_ylabel('Frequency')\n",
    "    plt.tight_layout(pad=0.1)\n",
    "    plt.show()\n",
    "    return best_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run local optimization with random start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_bnd = (-10,10)\n",
    "# Multistart through Latin hypercube sampling\n",
    "num_start = 100\n",
    "sampler=qmc.LatinHypercube(d=num_features_1*3,seed=215)\n",
    "sample = sampler.random(n=num_start)\n",
    "lhs_lb = [param_bnd[0]+1e-2 for i in range(num_features_1*3)]\n",
    "lhs_ub = [param_bnd[1]-1e-2 for i in range(num_features_1*3)]\n",
    "sample_scaled = qmc.scale(sample,lhs_lb,lhs_ub)\n",
    "method = 'SLSQP'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\til22008\\AppData\\Local\\Temp\\ipykernel_27308\\3869435058.py:27: RuntimeWarning: overflow encountered in exp\n",
      "  term_3 = I_nm /( I_nm + np.exp(  (X@w2@I_1m*1e2 -N) / (X@w3@I_1m*1e2 ) ))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best MSE: 0.033594893404891246\n",
      "best W: [ 7.03596188 10.          2.17241362  0.27174162  0.77326833  0.23650954\n",
      "  0.0510283  -0.27769904 -0.08401794  0.21918617  0.81236529  0.32075319\n",
      " -0.46260189 -0.70659084 -0.12588964 -0.06982564  0.8400457   0.13436245\n",
      "  0.43751592  0.81381628  0.09207146 -0.14281377  1.94144098  0.45387527\n",
      "  0.38198891 -0.06284043 -0.04480064  0.17307805 -0.55467671  0.09347333\n",
      " -0.45320554  0.49346718  0.17628045]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAELCAYAAACcbCGtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9p0lEQVR4nO3dd1QU5/4/8PciXSkCwoIiYu8YO5aoiCIar4WbiMEEDdHEgBFLjJ6rIZYENYkavShJvgY01xLJtaRiQcCooIKo0SAoolgoYoIICCI8vz/8MdcVVHZZ2AHfr3P2HGfm2Wc+s+N++OyUZxRCCAEiIiIikgU9XQdARERERP/D4oyIiIhIRlicEREREckIizMiIiIiGWFxRkRERCQjLM6IiIiIZITFGREREZGMsDgjIiIikhF9XQdQ28rLy3Hr1i2YmZlBoVDoOhwi0iIhBO7duwcHBwfo6dW/35rMT0QNV03yU4Mvzm7dugVHR0ddh0FEtej69eto0aKFrsNQG/MTUcOnSX5q8MWZmZkZgEcfjrm5uY6jISJtys/Ph6Ojo/Q9r2+Yn4garprkpwZfnFWcKjA3N2fyI2qg6uspQeYnooZPk/xU/y7SICIiImrAWJwRERERyQiLMyIiIiIZYXFGREREJCMszoiIiIhkpMHframujIwM5ObmVqutjY0NWrZsWcsRERH9jzo5Sh3MZ0TyweLsMRkZGejYsRPu3y+qVnsTE1NcvJjMhEZEdULdHKUO5jMi+WBx9pjc3Fzcv1+Eob6hsFS2f2bbvKxUxGx5F7m5uUxmRFQn1MlR6mA+I5IXFmdVsFS2h01LF12HQURUJeYoooaNNwQQERERyQiLMyIiIiIZYXFGREREJCMszoiIiIhkhMUZERERkYywOCMiIiKSERZnRERERDLC4oyIiIhIRnRanAUHB6NPnz4wMzODra0txo8fj5SUFJU2Q4cOhUKhUHm9++67OoqYiIiIqHbptDiLjY2Fv78/4uPjcfDgQZSWlmLkyJEoLCxUaTd9+nRkZmZKr9WrV+soYiIiIqLapdPHN0VGRqpMh4eHw9bWFomJiXj55Zel+aamplAqlXUdHhEREVGdk9U1Z3fv3gUAWFlZqczftm0bbGxs0LVrVyxatAhFRUVP7aOkpAT5+fkqLyIidZWVlWHJkiVwdnaGiYkJ2rRpg+XLl0MIIbURQuCjjz6Cvb09TExM4O7ujkuXLukwaiJqCGTz4PPy8nIEBgZi4MCB6Nq1qzT/9ddfh5OTExwcHHDu3Dl8+OGHSElJwe7du6vsJzg4GEuXLq2rsImogVq1ahU2bdqELVu2oEuXLkhISMC0adNgYWGB999/HwCwevVqrF+/Hlu2bIGzszOWLFkCDw8P/PnnnzA2NtbxFhBRfSWb4szf3x/nz5/H0aNHVebPmDFD+ne3bt1gb2+P4cOHIy0tDW3atKnUz6JFizB37lxpOj8/H46OjrUXOBE1SMePH8e4ceMwZswYAECrVq2wY8cOnDx5EsCjo2br1q3D4sWLMW7cOADA1q1bYWdnh71798Lb21tnsRNR/SaL05oBAQH4+eefER0djRYtWjyzbb9+/QAAly9frnK5kZERzM3NVV5EROoaMGAAoqKikJqaCgA4e/Ysjh49Ck9PTwBAeno6srKy4O7uLr3HwsIC/fr1Q1xcXJV98rILIqoOnR45E0Jg1qxZ2LNnD2JiYuDs7Pzc95w5cwYAYG9vX8vREdGLbOHChcjPz0fHjh3RqFEjlJWV4ZNPPoGPjw8AICsrCwBgZ2en8j47Oztp2ZN42QURVYdOizN/f39s374d+/btg5mZmZTQLCwsYGJigrS0NGzfvh2jR4+GtbU1zp07hzlz5uDll19G9+7ddRk6ETVwu3btwrZt27B9+3Z06dIFZ86cQWBgIBwcHODr66tRn7zsgoiqQ6fF2aZNmwA8Gmj2cWFhYZg6dSoMDQ1x6NAhrFu3DoWFhXB0dISXlxcWL16sg2iJ6EXywQcfYOHChdK1Y926dcO1a9cQHBwMX19faXif7OxslSP52dnZ6NGjR5V9GhkZwcjIqNZjJ6L6TeenNZ/F0dERsbGxdRQNEdH/FBUVQU9P9bLcRo0aoby8HADg7OwMpVKJqKgoqRjLz8/HiRMnMHPmzLoOl4gaENncrUlEJCdjx47FJ598gpYtW6JLly5ISkrCmjVr8NZbbwEAFAoFAgMDsWLFCrRr104aSsPBwQHjx4/XbfBEVK+xOCMiqsKGDRuwZMkSvPfee8jJyYGDgwPeeecdfPTRR1KbBQsWoLCwEDNmzEBeXh4GDRqEyMhIjnFGRDXC4oyIqApmZmZYt24d1q1b99Q2CoUCy5Ytw7Jly+ouMCJq8GQxzhkRERERPcLijIiIiEhGWJwRERERyQiLMyIiIiIZYXFGREREJCMszoiIiIhkhMUZERERkYywOCMiIiKSERZnRERERDLC4oyIiIhIRlicEREREckIizMiIiIiGWFxRkRERCQjLM6IiIiIZITFGREREZGMsDgjIiIikhEWZ0REREQywuKMiIiISEZYnBERERHJCIszIiIiIhlhcUZEREQkIyzOiIiIiGREp8VZcHAw+vTpAzMzM9ja2mL8+PFISUlRaVNcXAx/f39YW1ujSZMm8PLyQnZ2to4iJiIiIqpdOi3OYmNj4e/vj/j4eBw8eBClpaUYOXIkCgsLpTZz5szBTz/9hIiICMTGxuLWrVuYOHGiDqMmIiIiqj36ulx5ZGSkynR4eDhsbW2RmJiIl19+GXfv3sXmzZuxfft2uLm5AQDCwsLQqVMnxMfHo3///roIm4iIiKjWyOqas7t37wIArKysAACJiYkoLS2Fu7u71KZjx45o2bIl4uLiquyjpKQE+fn5Ki8iIiKi+kI2xVl5eTkCAwMxcOBAdO3aFQCQlZUFQ0NDWFpaqrS1s7NDVlZWlf0EBwfDwsJCejk6OtZ26ERERERaI5vizN/fH+fPn8fOnTtr1M+iRYtw9+5d6XX9+nUtRUhERERU+3R6zVmFgIAA/Pzzzzhy5AhatGghzVcqlXjw4AHy8vJUjp5lZ2dDqVRW2ZeRkRGMjIxqO2QiIiKiWqHTI2dCCAQEBGDPnj04fPgwnJ2dVZb36tULBgYGiIqKkualpKQgIyMDrq6udR0uERERUa3T6ZEzf39/bN++Hfv27YOZmZl0HZmFhQVMTExgYWEBPz8/zJ07F1ZWVjA3N8esWbPg6urKOzWJiIioQdJpcbZp0yYAwNChQ1Xmh4WFYerUqQCAtWvXQk9PD15eXigpKYGHhwc2btxYx5ESERER1Q2dFmdCiOe2MTY2RkhICEJCQuogIiIiIiLdks3dmkREcnPz5k1MmTIF1tbWMDExQbdu3ZCQkCAtF0Lgo48+gr29PUxMTODu7o5Lly7pMGIiaghYnBERVeHvv//GwIEDYWBggN9++w1//vknvvjiCzRt2lRqs3r1aqxfvx6hoaE4ceIEGjduDA8PDxQXF+swciKq7zQ6rXnlyhW0bt1a27EQEWmFNnLUqlWr4OjoiLCwMGne43eUCyGwbt06LF68GOPGjQMAbN26FXZ2dti7dy+8vb1rtH4ienFpdOSsbdu2GDZsGP7zn//wFyIRyY42ctSPP/6I3r1749VXX4WtrS1eeuklfPPNN9Ly9PR0ZGVlqTxezsLCAv369ePj5YioRjQqzk6fPo3u3btj7ty5UCqVeOedd3Dy5Eltx0ZEpBFt5KgrV65g06ZNaNeuHfbv34+ZM2fi/fffx5YtWwBAGvrHzs5O5X18vBwR1ZRGxVmPHj3w5Zdf4tatW/j222+RmZmJQYMGoWvXrlizZg1u376t7TiJiKpNGzmqvLwcPXv2xKeffoqXXnoJM2bMwPTp0xEaGqpxXHy8HBFVR41uCNDX18fEiRMRERGBVatW4fLly5g/fz4cHR3x5ptvIjMzU1txEhGprSY5yt7eHp07d1aZ16lTJ2RkZACA9Ai57OxslTbPe7ycubm5youI6Ek1Ks4SEhLw3nvvwd7eHmvWrMH8+fORlpaGgwcP4tatW9JFskREulCTHDVw4ECkpKSozEtNTYWTkxOARzcHKJVKlcfL5efn48SJE3y8HBHViEZ3a65ZswZhYWFISUnB6NGjsXXrVowePRp6eo9qPWdnZ4SHh6NVq1bajJWIqFq0kaPmzJmDAQMG4NNPP8Vrr72GkydP4uuvv8bXX38NAFAoFAgMDMSKFSvQrl07ODs7Y8mSJXBwcMD48ePrYCuJqKHSqDjbtGkT3nrrLUydOhX29vZVtrG1tcXmzZtrFBwRkSa0kaP69OmDPXv2YNGiRVi2bBmcnZ2xbt06+Pj4SG0WLFiAwsJCzJgxA3l5eRg0aBAiIyNhbGys9W0ioheHRsVZdUbANjQ0hK+vrybdExHViLZy1CuvvIJXXnnlqcsVCgWWLVuGZcuWqR0jEdHTaHTNWVhYGCIiIirNj4iIkG4zJyLSFeYoIqrPNCrOgoODYWNjU2m+ra0tPv300xoHRURUE8xRRFSfaVScZWRkqDzGpIKTk5N0mzkRka4wRxFRfaZRcWZra4tz585Vmn/27FlYW1vXOCgioppgjiKi+kyj4mzy5Ml4//33ER0djbKyMpSVleHw4cOYPXs2H/ZLRDrHHEVE9ZlGd2suX74cV69exfDhw6Gv/6iL8vJyvPnmm7yeg4h0jjmKiOozjYozQ0NDfP/991i+fDnOnj0LExMTdOvWTRo5m4hIl5ijiKg+06g4q9C+fXu0b99eW7EQEWkVcxQR1UcaFWdlZWUIDw9HVFQUcnJyUF5errL88OHDWgmOiEgTzFFEVJ9pVJzNnj0b4eHhGDNmDLp27QqFQqHtuIiINMYcRUT1mUbF2c6dO7Fr1y6MHj1a2/EQEdUYcxQR1WcaDaVhaGiItm3bajsWIiKtYI4iovpMo+Js3rx5+PLLLyGE0HY8REQ1xhxFRPWZRqc1jx49iujoaPz222/o0qULDAwMVJbv3r1bK8EREWmCOYqI6jONjpxZWlpiwoQJGDJkCGxsbGBhYaHyqq4jR45g7NixcHBwgEKhwN69e1WWT506FQqFQuU1atQoTUImoheItnIUEZEuaHTkLCwsTCsrLywshIuLC9566y1MnDixyjajRo1SWZ+RkZFW1k1EDZe2chQRkS5oPAjtw4cPERMTg7S0NLz++uswMzPDrVu3YG5ujiZNmlSrD09PT3h6ej6zjZGREZRKpaZhEtELShs5iohIFzQqzq5du4ZRo0YhIyMDJSUlGDFiBMzMzLBq1SqUlJQgNDRUawHGxMTA1tYWTZs2hZubG1asWAFra+unti8pKUFJSYk0nZ+fr7VYiKh+qMscRUSkbRpdczZ79mz07t0bf//9N0xMTKT5EyZMQFRUlNaCGzVqFLZu3YqoqCisWrUKsbGx8PT0RFlZ2VPfExwcrHJtiaOjo9biIaL6oa5yFBFRbdDoyNnvv/+O48ePw9DQUGV+q1atcPPmTa0EBgDe3t7Sv7t164bu3bujTZs2iImJwfDhw6t8z6JFizB37lxpOj8/nwUa0QumrnIUEVFt0OjIWXl5eZVHr27cuAEzM7MaB/U0rVu3ho2NDS5fvvzUNkZGRjA3N1d5EdGLRVc5iohIGzQqzkaOHIl169ZJ0wqFAgUFBQgKCqrVx6XcuHEDd+7cgb29fa2tg4jqP13lKCIibdDotOYXX3wBDw8PdO7cGcXFxXj99ddx6dIl2NjYYMeOHdXup6CgQOUoWHp6Os6cOQMrKytYWVlh6dKl8PLyglKpRFpaGhYsWIC2bdvCw8NDk7CJ6AWhrRxFRKQLGhVnLVq0wNmzZ7Fz506cO3cOBQUF8PPzg4+Pj8rFt8+TkJCAYcOGSdMV14r5+vpi06ZNOHfuHLZs2YK8vDw4ODhg5MiRWL58Occ6I6Jn0laOIiLSBY3HOdPX18eUKVNqtPKhQ4c+89l3+/fvr1H/RPTi0kaOIiLSBY2Ks61btz5z+ZtvvqlRMERE2sAcRUT1mUbF2ezZs1WmS0tLUVRUBENDQ5iamjLxEZFOMUcRUX2m0d2af//9t8qroKAAKSkpGDRoEC+2JSKdY44iovpMo+KsKu3atcPKlSsr/WIlIpID5igiqi+0VpwBjy7AvXXrlja7JCLSGuYoIqoPNLrm7Mcff1SZFkIgMzMT//73vzFw4ECtBEZEpCnmKCKqzzQqzsaPH68yrVAo0KxZM7i5ueGLL77QRlxERBpjjiKi+kyj4qy8vFzbcRARaQ1zFBHVZ1q95oyIqKFauXIlFAoFAgMDpXnFxcXw9/eHtbU1mjRpAi8vL2RnZ+suSCJqEDQ6clbxmKXqWLNmjSarICLSmLZz1KlTp/DVV1+he/fuKvPnzJmDX375BREREbCwsEBAQAAmTpyIY8eOqR0zEVEFjYqzpKQkJCUlobS0FB06dAAApKamolGjRujZs6fUTqFQaCdKIiI1aDNHFRQUwMfHB9988w1WrFghzb979y42b96M7du3w83NDQAQFhaGTp06IT4+Hv3799fyVhHRi0Kj4mzs2LEwMzPDli1b0LRpUwCPBn2cNm0aBg8ejHnz5mk1SCIidWgzR/n7+2PMmDFwd3dXKc4SExNRWloKd3d3aV7Hjh3RsmVLxMXFVVmclZSUoKSkRJrOz8/XZPOIqIHT6JqzL774AsHBwVLSA4CmTZtixYoVvBOKiHROWzlq586dOH36NIKDgysty8rKgqGhISwtLVXm29nZISsrq8r+goODYWFhIb0cHR2rHQsRvTg0Ks7y8/Nx+/btSvNv376Ne/fu1TgoIqKa0EaOun79OmbPno1t27bB2NhYK3EtWrQId+/elV7Xr1/XSr9E1LBoVJxNmDAB06ZNw+7du3Hjxg3cuHED//3vf+Hn54eJEydqO0YiIrVoI0clJiYiJycHPXv2hL6+PvT19REbG4v169dDX18fdnZ2ePDgAfLy8lTel52dDaVSWWWfRkZGMDc3V3kRET1Jo2vOQkNDMX/+fLz++usoLS191JG+Pvz8/PDZZ59pNUAiInVpI0cNHz4cf/zxh8q8adOmoWPHjvjwww/h6OgIAwMDREVFwcvLCwCQkpKCjIwMuLq6aneDiOiFolFxZmpqio0bN+Kzzz5DWloaAKBNmzZo3LixVoMjItKENnKUmZkZunbtqjKvcePGsLa2lub7+flh7ty5sLKygrm5OWbNmgVXV1feqUlENaJRcVYhMzMTmZmZePnll2FiYgIhBIfPICLZqO0ctXbtWujp6cHLywslJSXw8PDAxo0btdY/Eb2YNCrO7ty5g9deew3R0dFQKBS4dOkSWrduDT8/PzRt2pR3bBKRTtVWjoqJiVGZNjY2RkhICEJCQrQQNRHRIxrdEDBnzhwYGBggIyMDpqam0vxJkyYhMjJSa8EREWmCOYqI6jONjpwdOHAA+/fvR4sWLVTmt2vXDteuXdNKYEREmmKOIqL6TKMjZ4WFhSq/Riv89ddfMDIyqnFQREQ1wRxFRPWZRsXZ4MGDsXXrVmlaoVCgvLwcq1evxrBhw7QWHBGRJpijiKg+0+i05urVqzF8+HAkJCTgwYMHWLBgAS5cuIC//voLx44d03aMRERqYY4iovpMoyNnXbt2RWpqKgYNGoRx48ahsLAQEydORFJSEtq0aaPtGImI1MIcRUT1mdpHzkpLSzFq1CiEhobiX//6V41WfuTIEXz22WdITExEZmYm9uzZg/Hjx0vLhRAICgrCN998g7y8PAwcOBCbNm1Cu3btarReImq4tJmjiIh0Qe0jZwYGBjh37pxWVl5YWAgXF5enjhG0evVqrF+/HqGhoThx4gQaN24MDw8PFBcXa2X9RNTwaDNHERHpgkanNadMmYLNmzfXeOWenp5YsWIFJkyYUGmZEALr1q3D4sWLMW7cOHTv3h1bt27FrVu3sHfv3hqvm4gaLm3lKCIiXdDohoCHDx/i22+/xaFDh9CrV69Kz6tbs2ZNjQNLT09HVlYW3N3dpXkWFhbo168f4uLi4O3tXeX7SkpKUFJSIk3n5+fXOBa5y8jIQG5ubrXb29jYoGXLlrUYEZFu1UWOIiKqLWoVZ1euXEGrVq1w/vx59OzZEwCQmpqq0kZbz63LysoCANjZ2anMt7Ozk5ZVJTg4GEuXLtVKDPVBRkYGOnbshPv3i6r9HhMTU1y8mMwCjRqcusxRRES1Ra3irF27dsjMzER0dDSAR49CWb9+faUCSpcWLVqEuXPnStP5+flwdHTUYUS1Kzc3F/fvF2Gobygsle2f2z4vKxUxW95Fbm4uizNqcOpDjiIieh61ijMhhMr0b7/9hsLCQq0GVEGpVAIAsrOzYW9vL83Pzs5Gjx49nvo+IyOjF3IEcEtle9i0dNF1GEQ6VZc5ioiotmh0Q0CFJxOhNjk7O0OpVCIqKkqal5+fjxMnTsDV1bXW1ktEDUdt5igiotqi1pEzhUJR6XqNmly/UVBQgMuXL0vT6enpOHPmDKysrNCyZUsEBgZixYoVaNeuHZydnbFkyRI4ODiojIVGRFRB2zmKiEgX1D6tOXXqVOm0YXFxMd59991Kd0Lt3r27Wv0lJCSoPOeu4loxX19fhIeHY8GCBSgsLMSMGTOQl5eHQYMGITIyEsbGxuqETUQvCG3nKCIiXVCrOPP19VWZnjJlSo1WPnTo0GeedlAoFFi2bBmWLVtWo/UQ0YtB2zmKiEgX1CrOwsLCaisOIqIaY44iooagRjcEEBEREZF2sTgjIiIikhEWZ0REREQywuKMiIiISEZYnBERERHJiFp3a1LNZGRkIDc3t1ptbWxs+OxLIiKiFxCLszqSkZGBjh074f79omq1NzExxcWLySzQiIiIXjAszupIbm4u7t8vwlDfUFgq2z+zbV5WKmK2vIvc3FwWZ0RERC8YFmd1zFLZHjYtXXQdBhEREckUbwggIiIikhEWZ0REREQywuKMiIiISEZ4zdkLKjk5uVrtOKQHERFR3WJx9oIpys+GQqGHKVOmVKs9h/QgIiKqWyzOXjAPiu5CiHIO6UFERCRTvObsBVUxpMezXs8r3ogasuDgYPTp0wdmZmawtbXF+PHjkZKSotKmuLgY/v7+sLa2RpMmTeDl5YXs7GwdRUxEDQWLMyKiKsTGxsLf3x/x8fE4ePAgSktLMXLkSBQWFkpt5syZg59++gkRERGIjY3FrVu3MHHiRB1GTUQNAU9rEhFVITIyUmU6PDwctra2SExMxMsvv4y7d+9i8+bN2L59O9zc3AAAYWFh6NSpE+Lj49G/f39dhE1EDQCPnBERVcPdu3cBAFZWVgCAxMRElJaWwt3dXWrTsWNHtGzZEnFxcTqJkYgaBh45IyJ6jvLycgQGBmLgwIHo2rUrACArKwuGhoawtLRUaWtnZ4esrKwq+ykpKUFJSYk0nZ+fX2sxE1H9xeKMnotjomkmIyMDubm51WrLz07e/P39cf78eRw9erRG/QQHB2Pp0qVaioqIGioWZ/RUHBNNcxkZGejYsRPu3y+qVnt+dvIVEBCAn3/+GUeOHEGLFi2k+UqlEg8ePEBeXp7K0bPs7Gwolcoq+1q0aBHmzp0rTefn58PR0bHWYiei+onFGT0Vx0TTXG5uLu7fL+JnV48JITBr1izs2bMHMTExcHZ2Vlneq1cvGBgYICoqCl5eXgCAlJQUZGRkwNXVtco+jYyMYGRkVOuxE1H9Juvi7OOPP650CqBDhw64ePGijiJ6MVWMiUbq42dXf/n7+2P79u3Yt28fzMzMpOvILCwsYGJiAgsLC/j5+WHu3LmwsrKCubk5Zs2aBVdXV96pSUQ1IuviDAC6dOmCQ4cOSdP6+rIPmYgagE2bNgEAhg4dqjI/LCwMU6dOBQCsXbsWenp68PLyQklJCTw8PLBx48Y6jpSIGhrZVzr6+vpPvX6DiKi2CCGe28bY2BghISEICQmpg4iI6EUh+3HOLl26BAcHB7Ru3Ro+Pj7IyMjQdUhEREREtUbWR8769euH8PBwdOjQAZmZmVi6dCkGDx6M8+fPw8zMrMr31PU4QtUdZqK67ajmOIQFERHVZ7Iuzjw9PaV/d+/eHf369YOTkxN27doFPz+/Kt9TV+MIqTvMBNUNDmFBRET1nayLsydZWlqiffv2uHz58lPb1NU4QuoMMwEA1y8cQuLPn2o9DlLFISyIiKi+q1fFWUFBAdLS0vDGG288tU1djyNU3aES8rJS6yAaqsAhLIiIqL6S9Q0B8+fPR2xsLK5evYrjx49jwoQJaNSoESZPnqzr0IiIiIhqhayPnN24cQOTJ0/GnTt30KxZMwwaNAjx8fFo1qyZrkMjIiIiqhWyLs527typ6xCIiIiI6pSsi7MXXXWG35DbEB3VjUfdISyqOzyG3D4PIiIidbE4k6H6OEyHujGrM4SFusNjEBER1WcszmRInWE65DJEhzoxqzuEhTrDY8jl8yAiIt1SZ0ByddTF4OUszmSsOsNByG2IjtocwqI+fh5ERFT3avOMS10MXs7ijIiIiBoUdc64qKOuBi9ncUZEREQNUn0dkFzWg9ASERERvWh45Ix0prrDXtT28Bjq9F9SUlKtx4NxSA8iItIUizOqc3IZKkSTOBQKPQhRXotRERHRi47FGdU5dYbdAGpveAxN4+CQHkREVJtYnJHOVPdCzdoeHkPdODikBxER1SbeEEBEREQkIyzOiIiIiGSExRkRERGRjPCaMyKqdeo+464unl1HRCRXLM6IqFZp8oy7unh2HRGRXLE4I6Jape4z7urq2XVERHLF4oyI6kR9fcYdEVFd4w0BRERERDLC4oyIiIhIRlicEREREckIizMiIiIiGeENAUQykZycXK12JSUlMDIyqna/6rTn+GJERLrH4oxIx4rys6FQ6GHKlCnVaq9Q6EGI8mr3r057ji9GRKR7LM6IdOxB0V0IUV6tccCuXziExJ8/rfaYYeq05/hiRETyUC+Ks5CQEHz22WfIysqCi4sLNmzYgL59++o6LCKtqs44YHlZqdVuq0l70gxzFBFpk+xvCPj+++8xd+5cBAUF4fTp03BxcYGHhwdycnJ0HRoREXMUEWmd7IuzNWvWYPr06Zg2bRo6d+6M0NBQmJqa4ttvv9V1aEREzFFEpHWyLs4ePHiAxMREuLu7S/P09PTg7u6OuLg4HUZGRMQcRUS1Q9bXnOXm5qKsrAx2dnYq8+3s7HDx4sUq31NSUoKSkhJp+u7duwCA/Pz8566voKDg0XozzqK0pPCZbfOyLlW7rbrta6utXOKojzHLJY7ajPlu9mUAQGJiovRdeBY9PT2Ulz//LtCUlJRqx/B4HAUFBc/93lYsF0I8t9/aoG6Oqkl+AtTLUepQd9+rq7r/V+TSb232XR9jrs2+a6tfdfNOddVZfhIydvPmTQFAHD9+XGX+Bx98IPr27Vvle4KCggQAvvji6wV6Xb9+vS5SUiXq5ijmJ774evFemuQnWR85s7GxQaNGjZCdna0yPzs7G0qlssr3LFq0CHPnzpWmy8vL8ddff8Ha2hoKheKZ68vPz4ejoyOuX78Oc3Pzmm+AjnF75I3bU3NCCNy7dw8ODg51sr4nqZujapKfgIb3f+ZJ3L76r6FvozrbV5P8JOvizNDQEL169UJUVBTGjx8P4FEyi4qKQkBAQJXvMTIyqjQauqWlpVrrNTc3b1D/qbg98sbtqRkLC4s6W9eT1M1R2shPQMP7P/Mkbl/919C3sbrbp2l+knVxBgBz586Fr68vevfujb59+2LdunUoLCzEtGnTdB0aERFzFBFpneyLs0mTJuH27dv46KOPkJWVhR49eiAyMrLSBbhERLrAHEVE2ib74gwAAgICnnoaU5uMjIwQFBSk1kOl5YzbI2/cnoaDOUo7uH31X0PfxrraPoUQOroHnYiIiIgqkfUgtEREREQvGhZnRERERDLC4oyIiIhIRlicEREREckIi7P/LyQkBK1atYKxsTH69euHkydP6jokjX388cdQKBQqr44dO+o6rGo7cuQIxo4dCwcHBygUCuzdu1dluRACH330Eezt7WFiYgJ3d3dcunRJN8FWw/O2Z+rUqZX216hRo3QTbDUEBwejT58+MDMzg62tLcaPHy89x65CcXEx/P39YW1tjSZNmsDLy6vSKPqkft6JiIhAx44dYWxsjG7duuHXX39VWS7H74Y62/jNN99g8ODBaNq0KZo2bQp3d/dK7eX2fVFn+8LDwyvFbmxsrNJGbvtQne0bOnRope1TKBQYM2aM1EZO++95ubkqMTEx6NmzJ4yMjNC2bVuEh4dXaqONeoLFGYDvv/8ec+fORVBQEE6fPg0XFxd4eHggJydH16FprEuXLsjMzJReR48e1XVI1VZYWAgXFxeEhIRUuXz16tVYv349QkNDceLECTRu3BgeHh4oLi6u40ir53nbAwCjRo1S2V87duyowwjVExsbC39/f8THx+PgwYMoLS3FyJEjUVj4v4cLz5kzBz/99BMiIiIQGxuLW7duYeLEiTqMWn7UzTvHjx/H5MmT4efnh6SkJIwfPx7jx4/H+fPnpTZy+26ou40xMTGYPHkyoqOjERcXB0dHR4wcORI3b95UaSeX74smfzvMzc1VYr927ZrKcjntQ3W3b/fu3Srbdv78eTRq1AivvvqqSju57L/q5ObHpaenY8yYMRg2bBjOnDmDwMBAvP3229i/f7/URmv1hPqP+m14+vbtK/z9/aXpsrIy4eDgIIKDg3UYleaCgoKEi4uLrsPQCgBiz5490nR5eblQKpXis88+k+bl5eUJIyMjsWPHDh1EqJ4nt0cIIXx9fcW4ceN0Eo825OTkCAAiNjZWCPFofxgYGIiIiAipTXJysgAg4uLidBWm7Kibd1577TUxZswYlXn9+vUT77zzjhBCnt+NmubWhw8fCjMzM7FlyxZpnpy+L+puX1hYmLCwsHhqf3LbhzXdf2vXrhVmZmaioKBAmien/fe4qnLzkxYsWCC6dOmiMm/SpEnCw8NDmtZWPfHCHzl78OABEhMT4e7uLs3T09ODu7s74uLidBhZzVy6dAkODg5o3bo1fHx8kJGRoeuQtCI9PR1ZWVkq+8vCwgL9+vWr1/srJiYGtra26NChA2bOnIk7d+7oOqRqu3v3LgDAysoKAJCYmIjS0lKVfdSxY0e0bNmyXu8jbdIk78TFxam0BwAPDw+pvdy+G9rIrUVFRSgtLZX+b1WQw/dF0+0rKCiAk5MTHB0dMW7cOFy4cEFaJqd9qI39t3nzZnh7e6Nx48Yq8+Ww/zTxvO+gNuuJF744y83NRVlZWaVHrdjZ2SErK0tHUdVMv379EB4ejsjISGzatAnp6ekYPHgw7t27p+vQaqxinzSk/TVq1Chs3boVUVFRWLVqFWJjY+Hp6YmysjJdh/Zc5eXlCAwMxMCBA9G1a1cAj/aRoaFhpQd61+d9pG2a5J2srKxntpfbd0MbufXDDz+Eg4ODyh87uXxfNNm+Dh064Ntvv8W+ffvwn//8B+Xl5RgwYABu3LgBQF77sKb77+TJkzh//jzefvttlfly2X+aeNp3MD8/H/fv39dqPVEvHt9E6vH09JT+3b17d/Tr1w9OTk7YtWsX/Pz8dBgZVcXb21v6d7du3dC9e3e0adMGMTExGD58uA4jez5/f3+cP3++Xl3TSPXDypUrsXPnTsTExKhcNF+fvy+urq5wdXWVpgcMGIBOnTrhq6++wvLly3UYmfZt3rwZ3bp1Q9++fVXm1+f9V5de+CNnNjY2aNSoUaU7ybKzs6FUKnUUlXZZWlqiffv2uHz5sq5DqbGKfdKQ91fr1q1hY2Mj+/0VEBCAn3/+GdHR0WjRooU0X6lU4sGDB8jLy1Np35D2UU1pkneUSuUz28vtu1GT3Pr5559j5cqVOHDgALp37/7Mtrr6vmjjb4eBgQFeeuklKXY57cOabF9hYSF27txZrYMB9SXfAU//Dpqbm8PExESr9cQLX5wZGhqiV69eiIqKkuaVl5cjKipK5RdOfVZQUIC0tDTY29vrOpQac3Z2hlKpVNlf+fn5OHHiRIPZXzdu3MCdO3dku7+EEAgICMCePXtw+PBhODs7qyzv1asXDAwMVPZRSkoKMjIyGsw+qilN8o6rq6tKewA4ePCg1F5u3w1Nc+vq1auxfPlyREZGonfv3s9dj66+L9r421FWVoY//vhDil1O+7Am2xcREYGSkhJMmTLlueuRe7573PO+g1qtJ9S6faCB2rlzpzAyMhLh4eHizz//FDNmzBCWlpYiKytL16FpZN68eSImJkakp6eLY8eOCXd3d2FjYyNycnJ0HVq13Lt3TyQlJYmkpCQBQKxZs0YkJSWJa9euCSGEWLlypbC0tBT79u0T586dE+PGjRPOzs7i/v37Oo68as/annv37on58+eLuLg4kZ6eLg4dOiR69uwp2rVrJ4qLi3UdepVmzpwpLCwsRExMjMjMzJReRUVFUpt3331XtGzZUhw+fFgkJCQIV1dX4erqqsOo5ed5eeeNN94QCxculNofO3ZM6Ovri88//1wkJyeLoKAgYWBgIP744w+pjdy+G+pu48qVK4WhoaH44YcfVP5v3bt3TwghZPd9UXf7li5dKvbv3y/S0tJEYmKi8Pb2FsbGxuLChQtSGzntQ3W3r8KgQYPEpEmTKs2X2/573t+ahQsXijfeeENqf+XKFWFqaio++OADkZycLEJCQkSjRo1EZGSk1EZb9QSLs/9vw4YNomXLlsLQ0FD07dtXxMfH6zokjU2aNEnY29sLQ0ND0bx5czFp0iRx+fJlXYdVbdHR0QJApZevr68Q4tHt5kuWLBF2dnbCyMhIDB8+XKSkpOg26Gd41vYUFRWJkSNHimbNmgkDAwPh5OQkpk+fLusfBlVtCwARFhYmtbl//7547733RNOmTYWpqamYMGGCyMzM1F3QMvWsvDNkyBDp/3yFXbt2ifbt2wtDQ0PRpUsX8csvv6gsl+N3Q51tdHJyqvL/VlBQkBBCyPL7os72BQYGSm3t7OzE6NGjxenTp1X6k9s+VPf/6MWLFwUAceDAgUp9yW3/Pe9vja+vrxgyZEil9/To0UMYGhqK1q1bq+S9CtqoJxRCCKHesTYiIiIiqi0v/DVnRERERHLC4oyIiIhIRlicEREREckIizMiIiIiGWFxRkRERCQjLM6IiIiIZITFGREREZGMsDirZ1q1aoV169bVuE1NhYeHw9LSslbXAQB79+5F27Zt0ahRIwQGBtb6+p5l6NChOo+hOupq3xARUe1gcSYT169fx1tvvQUHBwcYGhrCyckJs2fPxp07d9Tu69SpU5gxY4bWYquq2Js0aRJSU1O1to6neeedd/DPf/4T169fx/Lly2t9fQAQExMDhUJR6cHdu3fvrrMYiIjU8fHHH8POzg4KhQJ79+6t1nseb3v16lUoFAqcOXOm1mKk6mNxJgNXrlxB7969cenSJezYsQOXL19GaGio9LDUv/76S63+mjVrBlNT01qK9hETExPY2trW6joKCgqQk5MDDw8PODg4wMzMrFbX9zxWVlY6j4GIquf27duYOXMmWrZsCSMjIyiVSnh4eODYsWO6Dk0rrl27BhMTExQUFCA5ORlLly7FV199hczMTHh6elarD3XaUt1icSYD/v7+MDQ0xIEDBzBkyBC0bNkSnp6eOHToEG7evIl//etfKu3v3buHyZMno3HjxmjevDlCQkJUlj95pCsvLw9vv/02mjVrBnNzc7i5ueHs2bMq7/npp5/Qp08fGBsbw8bGBhMmTADw6FTetWvXMGfOHCgUCigUCgCqp85SU1OhUChw8eJFlT7Xrl2LNm3aSNPnz5+Hp6cnmjRpAjs7O7zxxhvIzc2t8jOJiYmRCiE3NzcoFArExMTg448/Ro8ePVTarlu3Dq1atZKmp06divHjx+Pzzz+Hvb09rK2t4e/vj9LSUqlNSUkJPvzwQzg6OsLIyAht27bF5s2bcfXqVQwbNgwA0LRpUygUCkydOlX6LB4/rfn333/jzTffRNOmTWFqagpPT09cunRJWl7xGe3fvx+dOnVCkyZNMGrUKGRmZla5zeXl5WjRogU2bdqkMj8pKQl6enq4du0aAGDNmjXo1q0bGjduDEdHR7z33nsoKCioss/HP4/HBQYGYujQoSrrDg4OhrOzM0xMTODi4oIffvjhqX0SyZ2XlxeSkpKwZcsWpKam4scff8TQoUM1OhshR/v27cOwYcPQpEkTpKWlAQDGjRsHpVIJIyOjavWhTluqWyzOdOyvv/7C/v378d5778HExERlmVKphI+PD77//ns8/gjUzz77DC4uLkhKSsLChQsxe/ZsHDx48KnrePXVV5GTk4PffvsNiYmJ6NmzJ4YPHy4dkfvll18wYcIEjB49GklJSYiKikLfvn0BPDqV16JFCyxbtgyZmZlVFhbt27dH7969sW3bNpX527Ztw+uvvw7gUYHo5uaGl156CQkJCYiMjER2djZee+21KmMeMGAAUlJSAAD//e9/kZmZiQEDBjzv45RER0cjLS0N0dHR2LJlC8LDwxEeHi4tf/PNN7Fjxw6sX78eycnJ+Oqrr9CkSRM4Ojriv//9LwAgJSUFmZmZ+PLLL6tcx9SpU5GQkIAff/wRcXFxEEJg9OjRKkVgUVERPv/8c3z33Xc4cuQIMjIyMH/+/Cr709PTw+TJk7F9+3aV+du2bcPAgQPh5OQktVu/fj0uXLiALVu24PDhw1iwYEG1P5uqBAcHY+vWrQgNDcWFCxcwZ84cTJkyBbGxsTXql0gX8vLy8Pvvv2PVqlUYNmwYnJyc0LdvXyxatAj/+Mc/qjyFl5eXJ/0IrHDhwgW88sorMDc3h5mZGQYPHiwVQgDw7bffokuXLjAyMoK9vT0CAgJU+nvWj+KzZ89i2LBhMDMzg7m5OXr16oWEhAQAj46KjR07Fk2bNkXjxo3RpUsX/PrrryrbuG/fPvzjH//Axx9/jLFjxwJ4lBsqfkCfOnUKI0aMgI2NDSwsLDBkyBCcPn1apQ91ToFSHVP7UemkVfHx8QKA2LNnT5XL16xZIwCI7OxsIYQQTk5OYtSoUSptJk2aJDw9PaVpJycnsXbtWiGEEL///rswNzcXxcXFKu9p06aN+Oqrr4QQQri6ugofH5+nxvh4fxXCwsKEhYWFNL127VrRpk0baTolJUUAEMnJyUIIIZYvXy5Gjhyp0sf169cFAJGSklLlev/++28BQERHR0vzgoKChIuLi0q7tWvXCicnJ2na19dXODk5iYcPH0rzXn31VTFp0iSV2A4ePFjleqOjowUA8ffff6vMHzJkiJg9e7YQQojU1FQBQBw7dkxanpubK0xMTMSuXbuEEI8+IwDi8uXLUpuQkBBhZ2dX5XqFECIpKUkoFApx7do1IYQQZWVlonnz5mLTpk1PfU9ERISwtraWpp/cN76+vmLcuHEq75k9e7YYMmSIEEKI4uJiYWpqKo4fP67Sxs/PT0yePPmp6yWSq9LSUtGkSRMRGBhYKfcJIUR6eroAIJKSkqR5T+abGzduCCsrKzFx4kRx6tQpkZKSIr799ltx8eJFIYQQGzduFMbGxmLdunUiJSVFnDx5UiVPuru7i7Fjx4pTp06J1NRUMW/ePGFtbS3u3LkjhBCiS5cuYsqUKSI5OVmkpqaKXbt2iTNnzgghhBgzZowYMWKEOHfunEhLSxM//fSTiI2NVYnV0NBQ3Lx5U9y7d0/KNZmZmSIzM1MIIURUVJT47rvvRHJysvjzzz+Fn5+fsLOzE/n5+VI/j//tqeozId3R10VBSJWJx46MPY+rq2ul6afdnXn27FkUFBTA2tpaZf79+/elX4BnzpzB9OnT1Qv4Cd7e3pg/fz7i4+PRv39/bNu2DT179kTHjh2lOKKjo9GkSZNK701LS0P79u1rtP4ndenSBY0aNZKm7e3t8ccffwB4tL2NGjXCkCFDNO4/OTkZ+vr66NevnzTP2toaHTp0QHJysjTP1NRU5dSuvb09cnJyntpvjx490KlTJ2zfvh0LFy5EbGwscnJy8Oqrr0ptDh06hODgYFy8eBH5+fl4+PAhiouLUVRUpNG1hpcvX0ZRURFGjBihMv/Bgwd46aWX1O6PSNf09fURHh6O6dOnIzQ0FD179sSQIUPg7e2N7t27V6uPkJAQWFhYYOfOnTAwMAAAlTy1YsUKzJs3D7Nnz5bm9enTBwBw9OhRnDx5Ejk5OdJpw88//xx79+7FDz/8gBkzZiAjIwMffPCBlCPbtWsn9ZORkQEvLy9069YNANC6dWuV2H799Vd0794dDg4OACBdYqJUKqU2bm5uKu/5+uuvYWlpidjYWLzyyivV+gxId1ic6Vjbtm2hUCiQnJwsXef1uOTkZDRt2hTNmjXTqP+CggLY29urHKqvUPGFfvJ0qiaUSiXc3Nywfft29O/fH9u3b8fMmTNV4hg7dixWrVpV6b329vbVXo+enl6lQvbx04gVKpJpBYVCgfLycgDa2d7qqiqO5xXiPj4+UnG2fft2jBo1Siqur169ildeeQUzZ87EJ598AisrKxw9ehR+fn548OBBlcXZ8z6ziuvVfvnlFzRv3lylHa9HofrKy8sLY8aMwe+//474+Hj89ttvWL16Nf7v//5P5XrLpzlz5gwGDx5c6TsMADk5Obh16xaGDx9e5Xur86N47ty5ePvtt/Hdd9/B3d0dr776qvRD7v3338fMmTNx4MABuLu7w8vLS6WorDil+SzZ2dlYvHgxYmJikJOTg7KyMhQVFSEjI+O52066x2vOdMza2hojRozAxo0bcf/+fZVlWVlZ2LZtGyZNmiRdRwAA8fHxKu3i4+PRqVOnKvvv2bMnsrKyoK+vj7Zt26q8bGxsAADdu3dHVFTUU2M0NDREWVnZc7el4vq4uLg4XLlyBd7e3ipxXLhwAa1ataoUR+PGjZ/bd4VmzZohKytLpdhQ99bvbt26oby8/KnXUxkaGgLAM7e5U6dOePjwIU6cOCHNu3PnDlJSUtC5c2e14nnS66+/jvPnzyMxMRE//PADfHx8pGWJiYkoLy/HF198gf79+6N9+/a4devWM/tr1qxZpWsFH//MOnfuDCMjI2RkZFTaN46OjjXaFiJdMjY2xogRI7BkyRIcP34cU6dORVBQEPT0Hv3pezyPPPkj71k/4p73A6/iR/GZM2dUXikpKfjggw8APBr64sKFCxgzZgwOHz6Mzp07Y8+ePQCAt99+G1euXMEbb7yBP/74A71798aGDRsAPDqiHRkZ+dzizNfXF2fOnMGXX36J48eP48yZM7C2tsaDBw+e+T6SBxZnMvDvf/8bJSUl8PDwwJEjR3D9+nVERkZixIgRaN68OT755BOV9seOHcPq1auRmpqKkJAQREREqBxaf5y7uztcXV0xfvx4HDhwAFevXsXx48fxr3/9S7r4NCgoCDt27EBQUBCSk5Pxxx9/qBzhatWqFY4cOYKbN28+9e5KAJg4cSLu3buHmTNnYtiwYdIhd+DRHal//fUXJk+ejFOnTiEtLQ379+/HtGnTqlX4VRg6dChu376N1atXIy0tDSEhIfjtt9+q/f6K7fH19cVbb72FvXv3Ij09HTExMdi1axcAwMnJCQqFAj///DNu375d5Z2Q7dq1w7hx4zB9+nQcPXoUZ8+exZQpU9C8eXOMGzdOrXiqim/AgAHw8/NDWVmZShJu27YtSktLsWHDBly5cgXfffcdQkNDn9mfm5sbEhISsHXrVly6dAlBQUE4f/68tNzMzAzz58/HnDlzsGXLFqSlpeH06dPYsGEDtmzZUqNtIZKTzp07o7CwUDoT8fiPlid/5HXv3h2///57lUfmzczM0KpVq6f+qK3Oj2Lg0WnSOXPm4MCBA5g4cSLCwsKkZY6Ojnj33Xexe/duzJs3D9988w2AR3eyN23aFC4uLs/c1mPHjuH999/H6NGjpZsWnpW/SV5YnMlAu3btkJCQgNatW+O1115DmzZtMGPGDAwbNgxxcXGwsrJSaT9v3jwkJCTgpZdewooVK7BmzRp4eHhU2bdCocCvv/6Kl19+GdOmTUP79u3h7e2Na9euwc7ODsCjgiciIgI//vgjevToATc3N5w8eVLqY9myZbh69SratGnzzNOrZmZmGDt2LM6ePatytAcAHBwccOzYMZSVlWHkyJHo1q0bAgMDYWlpKf2KrY5OnTph48aNCAkJgYuLC06ePPnUux+fZdOmTfjnP/+J9957Dx07dsT06dNRWFgIAGjevDmWLl2KhQsXws7OTuUOrMeFhYWhV69eeOWVV+Dq6gohBH799dcqT4Ooy8fHB2fPnsWECRNUfqW7uLhgzZo1WLVqFbp27Ypt27YhODj4mX15eHhgyZIlWLBgAfr06YN79+7hzTffVGmzfPlyLFmyBMHBwejUqRNGjRqFX375Bc7OzjXeFqK6dufOHbi5ueE///kPzp07h/T0dERERGD16tUYN24cTExM0L9/f6xcuRLJycmIjY3F4sWLVfoICAhAfn4+vL29kZCQgEuXLuG7776T7iL/+OOP8cUXX2D9+vW4dOmS9IMGeP6P4vv37yMgIAAxMTG4du0ajh07hlOnTklnQAIDA7F//36kp6fj9OnTiI6Olpb9+OOPzz1qBjz6u/Ldd98hOTkZJ06cgI+PT51e0kE1pMObEaiWKJVK8c033+g6DCIinSguLhYLFy4UPXv2FBYWFsLU1FR06NBBLF68WBQVFQkhhPjzzz+Fq6urMDExET169BAHDhyodHf42bNnxciRI4WpqakwMzMTgwcPFmlpadLy0NBQ0aFDB2FgYCDs7e3FrFmzpGX5+fli1qxZwsHBQRgYGAhHR0fh4+MjMjIyRElJifD29haOjo7C0NBQODg4iICAAHH//n0hhBABAQGiTZs2wsjISDRr1ky88cYbIjc3VwghhKOjY6U7zffs2SOe/HN++vRp0bt3b2FsbCzatWsnIiIiKt15D96tKVsKIdS4TZBkraioCMeOHZNGwX7yrk4iIqq/Tp8+DTc3N9y+fVsrR+hJvnhaswH5+uuv4e3tjcDAQBZmREQNzMOHD7FhwwYWZi8AHjkjIiIikhEeOSMiIiKSERZnRERERDLC4oyIiIhIRlicEREREckIizMiIiIiGWFxRkRERCQjLM6IiIiIZITFGREREZGMsDgjIiIikpH/B8m/FLMTdw5hAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x250 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "cons = [\n",
    "    {'type':'ineq','fun':g1,'args':(X_train_PCA_1,)},\n",
    "    {'type':'ineq','fun':g2,'args':(X_train_PCA_1,)},\n",
    "    {'type':'ineq','fun':g3,'args':(X_train_PCA_1,)},\n",
    "    ]\n",
    "\n",
    "for i in range(len(sample_scaled)):\n",
    "    # print(f'Iteration: {i+1}')\n",
    "    W0 = sample_scaled[i]\n",
    "    alpha = 1e-9\n",
    "    rho = 0.95\n",
    "    # Minimization\n",
    "    res = minimize(end_to_end_loss,W0,\n",
    "                   args = (X_train_PCA_1,N_train,Q_train,a,alpha,rho),\n",
    "                   bounds = ((param_bnd, ) * len(W0)),\n",
    "                   constraints = cons,\n",
    "                   method = method,\n",
    "                   options={'disp': False,'maxiter':500})\n",
    "    results.append(res)\n",
    "\n",
    "best_result = visualize_opt_res(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " message: Optimization terminated successfully\n",
       " success: True\n",
       "  status: 0\n",
       "     fun: 0.033594893404891246\n",
       "       x: [ 7.036e+00  1.000e+01 ...  4.935e-01  1.763e-01]\n",
       "     nit: 173\n",
       "     jac: [ 4.255e-05 -4.185e-04 ... -1.149e-04 -1.557e-04]\n",
       "    nfev: 5920\n",
       "    njev: 173"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE Training: 1.713%\n",
      "Mean RMSE High-DoD: 2.464%\n",
      "Mean RMSE Low-DoD: 4.394%\n",
      "Mean MAE Training: 1.427%\n",
      "Mean MAE High-DoD: 1.971%\n",
      "Mean MAE Low-DoD: 3.774%\n"
     ]
    }
   ],
   "source": [
    "W_best_opt = best_result.x.reshape(num_features_1,3)\n",
    "b_train_hat_e2e_eln = X_train_PCA_1@W_best_opt\n",
    "b_test_in_hat_e2e_eln = X_test_in_PCA_1@W_best_opt\n",
    "b_test_out_hat_e2e_eln = X_test_out_PCA_1@W_best_opt\n",
    "\n",
    "# Evaluate training performance\n",
    "Q_train_hat_e2e_eln = Q_train.copy()\n",
    "RMSE_train_e2e_eln = []\n",
    "MAE_train_ele_eln = []\n",
    "for iii in range(len(Q_train)):\n",
    "    Q_true = Q_train[iii]\n",
    "    N_true = N_train[iii]\n",
    "    [b1,b2,b3] = b_train_hat_e2e_eln[iii]\n",
    "    Q_pred = empirical_model(a,b1,b2,b3,N_true)\n",
    "    Q_train_hat_e2e_eln[iii] = Q_pred\n",
    "\n",
    "    RMSE = root_mean_squared_error(Q_true,Q_pred)\n",
    "    RMSE_train_e2e_eln.append(RMSE)\n",
    "    MAE = mean_absolute_error(Q_true,Q_pred)\n",
    "    MAE_train_ele_eln.append(MAE)\n",
    "\n",
    "# Evaluate test performance\n",
    "Q_test_in_hat_e2e_eln = Q_test_in.copy()\n",
    "RMSE_test_in_e2e_eln = []\n",
    "MAE_test_in_e2e_eln = []\n",
    "for iii in range(len(Q_test_in)):\n",
    "    Q_true = Q_test_in[iii]\n",
    "    N_true = N_test_in[iii]\n",
    "    [b1,b2,b3] = np.abs(b_test_in_hat_e2e_eln[iii])\n",
    "    Q_pred = empirical_model(a,b1,b2,b3,N_true)\n",
    "    Q_test_in_hat_e2e_eln[iii] = Q_pred\n",
    "\n",
    "    RMSE = root_mean_squared_error(Q_true,Q_pred)\n",
    "    RMSE_test_in_e2e_eln.append(RMSE)\n",
    "    MAE = mean_absolute_error(Q_true,Q_pred)\n",
    "    MAE_test_in_e2e_eln.append(MAE)\n",
    "\n",
    "# Evaluate test performance\n",
    "Q_test_out_hat_e2e_eln = Q_test_out.copy()\n",
    "RMSE_test_out_e2e_eln = []\n",
    "MAE_test_out_e2e_eln = []\n",
    "for iii in range(len(Q_test_out)):\n",
    "    Q_true = Q_test_out[iii]\n",
    "    N_true = N_test_out[iii]\n",
    "    [b1,b2,b3] = np.abs(b_test_out_hat_e2e_eln[iii])\n",
    "    Q_pred = empirical_model(a,b1,b2,b3,N_true)\n",
    "    Q_test_out_hat_e2e_eln[iii] = Q_pred\n",
    "\n",
    "    RMSE = root_mean_squared_error(Q_true,Q_pred)\n",
    "    RMSE_test_out_e2e_eln.append(RMSE)\n",
    "    MAE = mean_absolute_error(Q_true,Q_pred)\n",
    "    MAE_test_out_e2e_eln.append(MAE)\n",
    "\n",
    "\n",
    "print(f'Mean RMSE Training: {np.mean(RMSE_train_e2e_eln)*100:.3f}%')\n",
    "print(f'Mean RMSE High-DoD: {np.mean(RMSE_test_in_e2e_eln)*100:.3f}%')\n",
    "print(f'Mean RMSE Low-DoD: {np.mean(RMSE_test_out_e2e_eln)*100:.3f}%')\n",
    "\n",
    "print(f'Mean MAE Training: {np.mean(MAE_train_ele_eln)*100:.3f}%')\n",
    "print(f'Mean MAE High-DoD: {np.mean(MAE_test_in_e2e_eln)*100:.3f}%')\n",
    "print(f'Mean MAE Low-DoD: {np.mean(MAE_test_out_e2e_eln)*100:.3f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b_train_pred_eln_df = pd.DataFrame(b_train_hat_e2e_eln * np.array([[1e-3,1e2,1e2]]*num_training_cells),index=training_cells)\n",
    "b_test_in_pred_eln_df = pd.DataFrame(b_test_in_hat_e2e_eln * np.array([[1e-3,1e2,1e2]]*num_test_in_cells),index=test_in_cells)\n",
    "b_test_out_pred_eln_df = pd.DataFrame(b_test_out_hat_e2e_eln * np.array([[1e-3,1e2,1e2]]*num_test_out_cells),index=test_out_cells)\n",
    "\n",
    "# Save as csv files\n",
    "b_train_pred_eln_df.to_csv(\"Empirical_parameter_results/b_train_e2e_eln.csv\")\n",
    "b_test_in_pred_eln_df.to_csv(\"Empirical_parameter_results/b_test_in_e2e_eln.csv\")\n",
    "b_test_out_pred_eln_df.to_csv(\"Empirical_parameter_results/b_test_out_e2e_eln.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_ = 42\n",
    "random.seed(seed_)\n",
    "torch.manual_seed(seed_)\n",
    "np.random.seed(seed_)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_cells_CV.pkl','rb') as f:\n",
    "    training_cells_CV = pickle.load(f)\n",
    "\n",
    "with open('val_cells_CV.pkl','rb') as f:\n",
    "    val_cells_CV = pickle.load(f)\n",
    "\n",
    "train_dataset_CV = []\n",
    "val_dataset_CV = []\n",
    "for fold in range(10):\n",
    "    train_cells = training_cells_CV[fold]\n",
    "    val_cells = val_cells_CV[fold]\n",
    "\n",
    "    X_train_fold = X_train_PCA[train_cells]\n",
    "    X_val_fold = X_train_PCA[val_cells]\n",
    "   \n",
    "    Y_train_fold = N_train[train_cells]\n",
    "    Y_val_fold = N_train[val_cells]\n",
    "    # print(Y_val_fold)\n",
    "\n",
    "    X_train_fold = torch.tensor(X_train_fold,dtype=torch.float32)\n",
    "    X_val_fold = torch.tensor(X_val_fold,dtype=torch.float32)\n",
    "\n",
    "    Y_train_fold = torch.tensor(Y_train_fold,dtype=torch.float32)\n",
    "    Y_val_fold = torch.tensor(Y_val_fold,dtype=torch.float32)\n",
    "\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_fold,Y_train_fold)\n",
    "    val_dataset = TensorDataset(X_val_fold,Y_val_fold)\n",
    "\n",
    "    train_dataset_CV.append(train_dataset)\n",
    "    val_dataset_CV.append(val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network\n",
    "class network(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(network, self).__init__()\n",
    "        # Define the layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(input_size, hidden_sizes[0]))  # Input layer\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            self.layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))  # Hidden layers\n",
    "        self.layers.append(nn.Linear(hidden_sizes[-1], output_size))  # Output layer\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = torch.relu(layer(x))\n",
    "        # x = self.layers[-1](x)\n",
    "        # x = torch.sigmoid(self.layers[-1](x))\n",
    "        # x = torch.relu(self.layers[-1](x))\n",
    "        x = torch.sigmoid(self.layers[-1](x)) * (40 - 1) + 1  # Outputs in range [1, 40]\n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for layer in self.layers[:-1]:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                torch.nn.init.kaiming_normal_(layer.weight, nonlinearity='relu')  # He Normal initialization\n",
    "                if layer.bias is not None:\n",
    "                    torch.nn.init.zeros_(layer.bias)  # Initialize bias to zero\n",
    "        # Xavier Normal initialization for the output layer (sigmoid activation)\n",
    "        torch.nn.init.xavier_normal_(self.layers[-1].weight)\n",
    "        torch.nn.init.zeros_(self.layers[-1].bias)\n",
    "\n",
    "        \n",
    "# Define the early stopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "# Define the input size and output size\n",
    "input_size = 10 # 10 pca features\n",
    "output_size = 3 # 3 empirical model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function informed by the empirical model\n",
    "def end_to_end_loss_NN(output,target,a=0.5,b_weight=[1e-3,1e2,1e2]):\n",
    "    # batch size and number of measurements\n",
    "    (batch_size,len_interp) = target.size()\n",
    "    # output size: (batch_size, n)\n",
    "    b1 = output[:,0].unsqueeze(1)\n",
    "    b2 = output[:,1].unsqueeze(1)\n",
    "    b3 = output[:,2].unsqueeze(1)\n",
    "    # Define ones\n",
    "    I_nm = torch.ones_like(target,dtype=torch.float32)\n",
    "    I_1m = torch.ones((1,len_interp),dtype=torch.float32)\n",
    "    # Define Q\n",
    "    Q = torch.linspace(1, 0.8, 21).unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "\n",
    "    term_2 = b1*I_1m*b_weight[0] * target ** a\n",
    "    term_3 = I_nm /( I_nm + torch.exp(  ((b2*I_1m*b_weight[1]) - target) / ((b3*I_1m)*b_weight[2] ) ))\n",
    "\n",
    "    loss = torch.mean((I_nm - term_2 - term_3 - Q )**2)\n",
    "    return loss\n",
    "\n",
    "def end_to_end_loss_NN_new(output, target,a=0.5,b_weight=[1e-3,1e2,1e2]):  # Assuming `a` is a predefined value\n",
    "    # batch size and number of measurements\n",
    "    (batch_size, len_interp) = target.size()\n",
    "    \n",
    "    # output size: (batch_size, n)\n",
    "    b1 = output[:, 0].unsqueeze(1)\n",
    "    b2 = output[:, 1].unsqueeze(1)\n",
    "    b3 = output[:, 2].unsqueeze(1)\n",
    "    \n",
    "    # Define ones\n",
    "    I_nm = torch.ones_like(target, dtype=torch.float32)\n",
    "    I_1m = torch.ones((1, len_interp), dtype=torch.float32)\n",
    "    \n",
    "    # Define Q\n",
    "    Q = torch.linspace(1, 0.8, 21).unsqueeze(0).repeat(batch_size, 1)\n",
    "    \n",
    "    # Safe term_2 calculation\n",
    "    term_2 = b1 * I_1m * b_weight[0] * torch.pow(target, a)  # Using torch.pow for stability\n",
    "    \n",
    "    # Clamp inputs to exp to avoid overflow/underflow\n",
    "    exp_input = ((b2 * I_1m * b_weight[1]) - target) / ((b3 * I_1m * b_weight[2]) + 1e-6)\n",
    "    exp_input_clamped = torch.clamp(exp_input, min = -87, max = 88) # The maximum range without causing overflow\n",
    "    \n",
    "    # Safe term_3 calculation with clamping\n",
    "    term_3 = I_nm / (I_nm + torch.exp(exp_input_clamped))\n",
    "    \n",
    "    # Loss calculation\n",
    "    loss = torch.mean((I_nm - term_2 - term_3 - Q) ** 2)\n",
    "    \n",
    "    return loss * 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform hyperparameter optimization via optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:27:22,001] A new study created in memory with name: no-name-513ab995-b112-4ece-b2df-0c6d071dfedc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 186\n",
      "Early stopping at epoch 190\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 257\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 307\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:27:42,648] Trial 0 finished with value: 1.0271456763148308 and parameters: {'lr': 0.0013292918943162175, 'num_neuron': 15, 'num_layer': 4, 'batch_size': 45, 'weight_decay': 4.2079886696066345e-06}. Best is trial 0 with value: 1.0271456763148308.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 481\n",
      "Validation loss: [0.1315794140100479, 7.4324564933776855, 0.902696430683136, 0.10137341171503067, 0.10704435408115387, 0.07484819740056992, 0.06394924223423004, 0.04294896125793457, 0.8142887353897095, 0.6002715229988098]\n",
      "Early stopping at epoch 473\n",
      "Early stopping at epoch 224\n",
      "Early stopping at epoch 2105\n",
      "Early stopping at epoch 1751\n",
      "Early stopping at epoch 837\n",
      "Early stopping at epoch 900\n",
      "Early stopping at epoch 472\n",
      "Early stopping at epoch 449\n",
      "Early stopping at epoch 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:28:33,535] Trial 1 finished with value: 0.08515023961663246 and parameters: {'lr': 0.00029375384576328325, 'num_neuron': 5, 'num_layer': 5, 'batch_size': 45, 'weight_decay': 0.0006796578090758161}. Best is trial 1 with value: 0.08515023961663246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 243\n",
      "Validation loss: [0.12132223695516586, 0.07766253501176834, 0.13073350489139557, 0.06593866646289825, 0.0702921524643898, 0.08586601912975311, 0.056703418493270874, 0.11062336713075638, 0.0732959657907486, 0.059064529836177826]\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 224\n",
      "Early stopping at epoch 277\n",
      "Early stopping at epoch 1597\n",
      "Early stopping at epoch 334\n",
      "Early stopping at epoch 196\n",
      "Early stopping at epoch 456\n",
      "Early stopping at epoch 277\n",
      "Early stopping at epoch 202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:29:19,195] Trial 2 finished with value: 0.13679461665451526 and parameters: {'lr': 0.00011527987128232407, 'num_neuron': 15, 'num_layer': 5, 'batch_size': 26, 'weight_decay': 5.337032762603957e-06}. Best is trial 1 with value: 0.08515023961663246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 243\n",
      "Validation loss: [0.10130900144577026, 0.07493405789136887, 0.0904245674610138, 0.06209999695420265, 0.129887655377388, 0.05625500530004501, 0.34291547536849976, 0.10172905027866364, 0.21464377641677856, 0.19374758005142212]\n",
      "Early stopping at epoch 713\n",
      "Early stopping at epoch 325\n",
      "Early stopping at epoch 435\n",
      "Early stopping at epoch 801\n",
      "Early stopping at epoch 224\n",
      "Early stopping at epoch 437\n",
      "Early stopping at epoch 1060\n",
      "Early stopping at epoch 567\n",
      "Early stopping at epoch 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:30:02,406] Trial 3 finished with value: 0.09656896702945232 and parameters: {'lr': 0.0003549878832196505, 'num_neuron': 8, 'num_layer': 4, 'batch_size': 37, 'weight_decay': 1.461896279370496e-05}. Best is trial 1 with value: 0.08515023961663246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 496\n",
      "Validation loss: [0.11317719519138336, 0.09551075845956802, 0.061544496566057205, 0.0931231901049614, 0.09679768979549408, 0.056781962513923645, 0.08411350101232529, 0.24677105247974396, 0.05732250213623047, 0.060547322034835815]\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 200\n",
      "Early stopping at epoch 223\n",
      "Early stopping at epoch 272\n",
      "Early stopping at epoch 203\n",
      "Early stopping at epoch 229\n",
      "Early stopping at epoch 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:30:19,991] Trial 4 finished with value: 0.15260736346244813 and parameters: {'lr': 0.006847920095574782, 'num_neuron': 6, 'num_layer': 3, 'batch_size': 33, 'weight_decay': 6.672367170464208e-05}. Best is trial 1 with value: 0.08515023961663246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 191\n",
      "Validation loss: [0.07536094635725021, 0.08206716924905777, 0.8203577399253845, 0.09734486043453217, 0.06678547710180283, 0.05046502873301506, 0.0635671615600586, 0.04895578697323799, 0.07867377251386642, 0.14249569177627563]\n",
      "Early stopping at epoch 186\n",
      "Early stopping at epoch 198\n",
      "Early stopping at epoch 216\n",
      "Early stopping at epoch 184\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 277\n",
      "Early stopping at epoch 186\n",
      "Early stopping at epoch 238\n",
      "Early stopping at epoch 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:30:35,674] Trial 5 finished with value: 0.07299568615853787 and parameters: {'lr': 0.0226739865237804, 'num_neuron': 7, 'num_layer': 4, 'batch_size': 45, 'weight_decay': 1.5339162591163623e-06}. Best is trial 5 with value: 0.07299568615853787.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 248\n",
      "Validation loss: [0.06675001233816147, 0.05115283280611038, 0.04222026467323303, 0.18953098356723785, 0.12244457751512527, 0.05409505218267441, 0.048009276390075684, 0.04311108961701393, 0.05665355175733566, 0.05598922073841095]\n",
      "Early stopping at epoch 289\n",
      "Early stopping at epoch 416\n",
      "Early stopping at epoch 238\n",
      "Early stopping at epoch 263\n",
      "Early stopping at epoch 306\n",
      "Early stopping at epoch 206\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 499\n",
      "Early stopping at epoch 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:30:52,758] Trial 6 finished with value: 0.06957202926278114 and parameters: {'lr': 0.006647135865318032, 'num_neuron': 6, 'num_layer': 2, 'batch_size': 62, 'weight_decay': 0.007286653737491046}. Best is trial 6 with value: 0.06957202926278114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 273\n",
      "Validation loss: [0.08204654604196548, 0.09337948262691498, 0.0782310739159584, 0.07235345244407654, 0.07635129988193512, 0.06246449798345566, 0.05845978856086731, 0.042678892612457275, 0.06312097609043121, 0.06663428246974945]\n",
      "Early stopping at epoch 200\n",
      "Early stopping at epoch 217\n",
      "Early stopping at epoch 236\n",
      "Early stopping at epoch 206\n",
      "Early stopping at epoch 184\n",
      "Early stopping at epoch 199\n",
      "Early stopping at epoch 290\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:31:06,696] Trial 7 finished with value: 0.11003685034811497 and parameters: {'lr': 0.026619018884890575, 'num_neuron': 8, 'num_layer': 2, 'batch_size': 49, 'weight_decay': 5.762487216478604e-05}. Best is trial 6 with value: 0.06957202926278114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 182\n",
      "Validation loss: [0.07566188275814056, 0.10327158868312836, 0.2104216068983078, 0.2350611835718155, 0.10446396470069885, 0.12208595871925354, 0.04922209680080414, 0.07759249210357666, 0.059985700994729996, 0.06260202825069427]\n",
      "Early stopping at epoch 1166\n",
      "Early stopping at epoch 1062\n",
      "Early stopping at epoch 1725\n",
      "Early stopping at epoch 1095\n",
      "Early stopping at epoch 2658\n",
      "Early stopping at epoch 2376\n",
      "Early stopping at epoch 1606\n",
      "Early stopping at epoch 914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:32:32,550] Trial 8 finished with value: 0.0805358685553074 and parameters: {'lr': 0.00023233503515390126, 'num_neuron': 10, 'num_layer': 2, 'batch_size': 60, 'weight_decay': 1.0842262717330169e-05}. Best is trial 6 with value: 0.06957202926278114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 1726\n",
      "Validation loss: [0.05513498932123184, 0.15216179192066193, 0.08566036075353622, 0.10487749427556992, 0.09243275225162506, 0.0567048154771328, 0.052727099508047104, 0.06597225368022919, 0.08276263624429703, 0.0569244921207428]\n",
      "Early stopping at epoch 197\n",
      "Early stopping at epoch 190\n",
      "Early stopping at epoch 703\n",
      "Early stopping at epoch 205\n",
      "Early stopping at epoch 217\n",
      "Early stopping at epoch 262\n",
      "Early stopping at epoch 242\n",
      "Early stopping at epoch 220\n",
      "Early stopping at epoch 257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:32:52,518] Trial 9 finished with value: 0.17686087414622306 and parameters: {'lr': 0.009717775305059635, 'num_neuron': 8, 'num_layer': 4, 'batch_size': 42, 'weight_decay': 5.4880470007660465e-06}. Best is trial 6 with value: 0.06957202926278114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 218\n",
      "Validation loss: [0.07430867850780487, 0.07407091557979584, 0.026400160044431686, 0.09190292656421661, 1.023773193359375, 0.06665492802858353, 0.054186925292015076, 0.23469112813472748, 0.0676606148481369, 0.05495927110314369]\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 195\n",
      "Early stopping at epoch 225\n",
      "Early stopping at epoch 234\n",
      "Early stopping at epoch 198\n",
      "Early stopping at epoch 203\n",
      "Early stopping at epoch 215\n",
      "Early stopping at epoch 184\n",
      "Early stopping at epoch 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:33:05,775] Trial 10 finished with value: 0.05996076874434948 and parameters: {'lr': 0.0732903453065306, 'num_neuron': 12, 'num_layer': 3, 'batch_size': 62, 'weight_decay': 0.008621541870304558}. Best is trial 10 with value: 0.05996076874434948.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 244\n",
      "Validation loss: [0.06676240265369415, 0.09209444373846054, 0.05346925929188728, 0.06736569851636887, 0.06380492448806763, 0.07460156828165054, 0.04315738007426262, 0.040700219571590424, 0.05728455260396004, 0.040367238223552704]\n",
      "Early stopping at epoch 194\n",
      "Early stopping at epoch 184\n",
      "Early stopping at epoch 226\n",
      "Early stopping at epoch 194\n",
      "Early stopping at epoch 212\n",
      "Early stopping at epoch 212\n",
      "Early stopping at epoch 186\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:33:20,078] Trial 11 finished with value: 0.059244954586029054 and parameters: {'lr': 0.05320889423231188, 'num_neuron': 12, 'num_layer': 3, 'batch_size': 63, 'weight_decay': 0.009788450409471175}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 306\n",
      "Validation loss: [0.06435614824295044, 0.10168595612049103, 0.04946873337030411, 0.06811335682868958, 0.05882742255926132, 0.06758475303649902, 0.0460389219224453, 0.04650545120239258, 0.04741344973444939, 0.04245535284280777]\n",
      "Early stopping at epoch 212\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 214\n",
      "Early stopping at epoch 215\n",
      "Early stopping at epoch 187\n",
      "Early stopping at epoch 184\n",
      "Early stopping at epoch 217\n",
      "Early stopping at epoch 222\n",
      "Early stopping at epoch 186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:33:33,820] Trial 12 finished with value: 0.06290958449244499 and parameters: {'lr': 0.09483778100691889, 'num_neuron': 12, 'num_layer': 3, 'batch_size': 56, 'weight_decay': 0.00946264497974616}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 208\n",
      "Validation loss: [0.0725758820772171, 0.11807969212532043, 0.04353683441877365, 0.0698637142777443, 0.06351818889379501, 0.06522741168737411, 0.051998354494571686, 0.04835415631532669, 0.055402062833309174, 0.04053954780101776]\n",
      "Early stopping at epoch 264\n",
      "Early stopping at epoch 196\n",
      "Early stopping at epoch 239\n",
      "Early stopping at epoch 202\n",
      "Early stopping at epoch 200\n",
      "Early stopping at epoch 211\n",
      "Early stopping at epoch 185\n",
      "Early stopping at epoch 186\n",
      "Early stopping at epoch 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:33:47,521] Trial 13 finished with value: 0.09182655215263366 and parameters: {'lr': 0.0778780188885582, 'num_neuron': 12, 'num_layer': 3, 'batch_size': 56, 'weight_decay': 0.0010280147799031692}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 188\n",
      "Validation loss: [0.08396917581558228, 0.15089663863182068, 0.04043940082192421, 0.1450318992137909, 0.07645333558320999, 0.057765983045101166, 0.06379619240760803, 0.0432625375688076, 0.08627167344093323, 0.1703786849975586]\n",
      "Early stopping at epoch 266\n",
      "Early stopping at epoch 208\n",
      "Early stopping at epoch 235\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 219\n",
      "Early stopping at epoch 219\n",
      "Early stopping at epoch 219\n",
      "Early stopping at epoch 187\n",
      "Early stopping at epoch 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:34:14,515] Trial 14 finished with value: 0.07946799658238887 and parameters: {'lr': 0.033371299037816805, 'num_neuron': 12, 'num_layer': 3, 'batch_size': 20, 'weight_decay': 0.0012237594247191323}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 187\n",
      "Validation loss: [0.06566549092531204, 0.19243745505809784, 0.03233259916305542, 0.08574805408716202, 0.06669913977384567, 0.05924639478325844, 0.09453244507312775, 0.09157564491033554, 0.05279545485973358, 0.05364728718996048]\n",
      "Early stopping at epoch 730\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 643\n",
      "Early stopping at epoch 209\n",
      "Early stopping at epoch 357\n",
      "Early stopping at epoch 214\n",
      "Early stopping at epoch 327\n",
      "Early stopping at epoch 266\n",
      "Early stopping at epoch 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:34:35,194] Trial 15 finished with value: 0.656513973325491 and parameters: {'lr': 0.0018561860486787612, 'num_neuron': 13, 'num_layer': 3, 'batch_size': 64, 'weight_decay': 0.0033762283403411197}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 298\n",
      "Validation loss: [0.18905048072338104, 5.301029205322266, 0.18667687475681305, 0.08902163803577423, 0.07452427595853806, 0.05595709756016731, 0.45971059799194336, 0.12202025204896927, 0.06024252623319626, 0.026906784623861313]\n",
      "Early stopping at epoch 193\n",
      "Early stopping at epoch 184\n",
      "Early stopping at epoch 219\n",
      "Early stopping at epoch 205\n",
      "Early stopping at epoch 207\n",
      "Early stopping at epoch 188\n",
      "Early stopping at epoch 204\n",
      "Early stopping at epoch 216\n",
      "Early stopping at epoch 237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:34:47,401] Trial 16 finished with value: 0.111894516274333 and parameters: {'lr': 0.04122012482760306, 'num_neuron': 10, 'num_layer': 2, 'batch_size': 51, 'weight_decay': 0.00023108579821866317}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 226\n",
      "Validation loss: [0.05146710202097893, 0.10887330770492554, 0.13480471074581146, 0.06350913643836975, 0.08181966841220856, 0.08974432945251465, 0.050413601100444794, 0.3994828462600708, 0.07523243874311447, 0.06359802186489105]\n",
      "Early stopping at epoch 185\n",
      "Early stopping at epoch 213\n",
      "Early stopping at epoch 234\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 201\n",
      "Early stopping at epoch 190\n",
      "Early stopping at epoch 250\n",
      "Early stopping at epoch 191\n",
      "Early stopping at epoch 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:35:01,382] Trial 17 finished with value: 0.136982698738575 and parameters: {'lr': 0.011389740369231415, 'num_neuron': 13, 'num_layer': 3, 'batch_size': 55, 'weight_decay': 0.0026498961874338134}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 208\n",
      "Validation loss: [0.21488717198371887, 0.0662737786769867, 0.06552577018737793, 0.3043577969074249, 0.3288840055465698, 0.09052293002605438, 0.060891274362802505, 0.135724738240242, 0.06875913590192795, 0.03400038555264473]\n",
      "Early stopping at epoch 212\n",
      "Early stopping at epoch 201\n",
      "Early stopping at epoch 220\n",
      "Early stopping at epoch 188\n",
      "Early stopping at epoch 187\n",
      "Early stopping at epoch 207\n",
      "Early stopping at epoch 235\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:35:16,152] Trial 18 finished with value: 0.07886622175574302 and parameters: {'lr': 0.05181975512011711, 'num_neuron': 11, 'num_layer': 4, 'batch_size': 64, 'weight_decay': 0.00033596824144542867}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 183\n",
      "Validation loss: [0.0542217455804348, 0.1094016581773758, 0.03868504613637924, 0.11465795338153839, 0.11254950612783432, 0.047329969704151154, 0.08098477870225906, 0.13247798383235931, 0.047666870057582855, 0.050686705857515335]\n",
      "Early stopping at epoch 249\n",
      "Early stopping at epoch 523\n",
      "Early stopping at epoch 240\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 1068\n",
      "Early stopping at epoch 200\n",
      "Early stopping at epoch 1406\n",
      "Early stopping at epoch 186\n",
      "Early stopping at epoch 588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:35:45,762] Trial 19 finished with value: 0.6723136950284243 and parameters: {'lr': 0.0033192649217672256, 'num_neuron': 14, 'num_layer': 2, 'batch_size': 52, 'weight_decay': 0.003274664472073347}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 738\n",
      "Validation loss: [0.0791550874710083, 6.009213447570801, 0.03940689191222191, 0.09263925999403, 0.06541959196329117, 0.06657566875219345, 0.054536446928977966, 0.18848121166229248, 0.07789343595504761, 0.04981590807437897]\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 184\n",
      "Early stopping at epoch 188\n",
      "Early stopping at epoch 202\n",
      "Early stopping at epoch 248\n",
      "Early stopping at epoch 213\n",
      "Early stopping at epoch 272\n",
      "Early stopping at epoch 230\n",
      "Early stopping at epoch 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:35:59,230] Trial 20 finished with value: 0.07046094201505185 and parameters: {'lr': 0.016560905214446857, 'num_neuron': 10, 'num_layer': 3, 'batch_size': 59, 'weight_decay': 0.008296546993839084}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 246\n",
      "Validation loss: [0.07629092782735825, 0.12131491303443909, 0.051561761647462845, 0.10181799530982971, 0.08012279123067856, 0.0775483250617981, 0.0563189797103405, 0.04093170166015625, 0.05969993770122528, 0.03900208696722984]\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 239\n",
      "Early stopping at epoch 238\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 268\n",
      "Early stopping at epoch 212\n",
      "Early stopping at epoch 193\n",
      "Early stopping at epoch 261\n",
      "Early stopping at epoch 198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:36:13,330] Trial 21 finished with value: 0.06628813594579697 and parameters: {'lr': 0.07973419605186383, 'num_neuron': 12, 'num_layer': 3, 'batch_size': 57, 'weight_decay': 0.00882660286434854}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 198\n",
      "Validation loss: [0.08106102049350739, 0.16593557596206665, 0.03467947244644165, 0.06633221358060837, 0.06691426783800125, 0.0677613839507103, 0.048678919672966, 0.04027924686670303, 0.051742617040872574, 0.03949664160609245]\n",
      "Early stopping at epoch 205\n",
      "Early stopping at epoch 188\n",
      "Early stopping at epoch 215\n",
      "Early stopping at epoch 225\n",
      "Early stopping at epoch 339\n",
      "Early stopping at epoch 208\n",
      "Early stopping at epoch 202\n",
      "Early stopping at epoch 205\n",
      "Early stopping at epoch 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:36:28,557] Trial 22 finished with value: 0.07763646878302097 and parameters: {'lr': 0.09454666095702148, 'num_neuron': 11, 'num_layer': 3, 'batch_size': 54, 'weight_decay': 0.0021366574250801696}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 219\n",
      "Validation loss: [0.10068017244338989, 0.08466611057519913, 0.0640370100736618, 0.08571566641330719, 0.16146549582481384, 0.050112854689359665, 0.07291296124458313, 0.04824434965848923, 0.06130778789520264, 0.04722227901220322]\n",
      "Early stopping at epoch 188\n",
      "Early stopping at epoch 195\n",
      "Early stopping at epoch 193\n",
      "Early stopping at epoch 214\n",
      "Early stopping at epoch 271\n",
      "Early stopping at epoch 208\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:36:43,824] Trial 23 finished with value: 0.06379643976688384 and parameters: {'lr': 0.05062164720943311, 'num_neuron': 13, 'num_layer': 3, 'batch_size': 59, 'weight_decay': 0.004374111838811446}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 382\n",
      "Validation loss: [0.07085254788398743, 0.12292160093784332, 0.047979071736335754, 0.054639268666505814, 0.07162220776081085, 0.04744257777929306, 0.06873004883527756, 0.04906307905912399, 0.07202228158712387, 0.03269171342253685]\n",
      "Early stopping at epoch 226\n",
      "Early stopping at epoch 189\n",
      "Early stopping at epoch 224\n",
      "Early stopping at epoch 342\n",
      "Early stopping at epoch 211\n",
      "Early stopping at epoch 206\n",
      "Early stopping at epoch 227\n",
      "Early stopping at epoch 217\n",
      "Early stopping at epoch 186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:36:58,951] Trial 24 finished with value: 0.0813774086534977 and parameters: {'lr': 0.09976865637630772, 'num_neuron': 11, 'num_layer': 4, 'batch_size': 49, 'weight_decay': 0.0003947453425515755}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 184\n",
      "Validation loss: [0.07175444066524506, 0.19354024529457092, 0.059701547026634216, 0.07061316072940826, 0.06246031075716019, 0.05635103955864906, 0.051023006439208984, 0.12266548722982407, 0.059626709669828415, 0.06603813916444778]\n",
      "Early stopping at epoch 220\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 238\n",
      "Early stopping at epoch 207\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 199\n",
      "Early stopping at epoch 185\n",
      "Early stopping at epoch 187\n",
      "Early stopping at epoch 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:37:12,436] Trial 25 finished with value: 0.13162030931562185 and parameters: {'lr': 0.017200725193754856, 'num_neuron': 14, 'num_layer': 3, 'batch_size': 64, 'weight_decay': 0.0014857781035037209}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 200\n",
      "Validation loss: [0.08834598958492279, 0.08664398640394211, 0.018615910783410072, 0.3375689387321472, 0.21215450763702393, 0.05380659177899361, 0.09715016931295395, 0.2904994487762451, 0.06435592472553253, 0.06706162542104721]\n",
      "Early stopping at epoch 196\n",
      "Early stopping at epoch 235\n",
      "Early stopping at epoch 223\n",
      "Early stopping at epoch 232\n",
      "Early stopping at epoch 208\n",
      "Early stopping at epoch 185\n",
      "Early stopping at epoch 190\n",
      "Early stopping at epoch 213\n",
      "Early stopping at epoch 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:37:26,444] Trial 26 finished with value: 0.0628313485532999 and parameters: {'lr': 0.04940452771292392, 'num_neuron': 9, 'num_layer': 2, 'batch_size': 60, 'weight_decay': 0.009519029611951639}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 235\n",
      "Validation loss: [0.07768984138965607, 0.12062283605337143, 0.055620063096284866, 0.062391020357608795, 0.05504516884684563, 0.055064063519239426, 0.05318659171462059, 0.05040968582034111, 0.06177538260817528, 0.03650883212685585]\n",
      "Early stopping at epoch 230\n",
      "Early stopping at epoch 236\n",
      "Early stopping at epoch 233\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 283\n",
      "Early stopping at epoch 187\n",
      "Early stopping at epoch 188\n",
      "Early stopping at epoch 218\n",
      "Early stopping at epoch 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:37:39,644] Trial 27 finished with value: 0.06832930967211723 and parameters: {'lr': 0.04824994745039456, 'num_neuron': 9, 'num_layer': 2, 'batch_size': 60, 'weight_decay': 0.005133811313556047}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 199\n",
      "Validation loss: [0.06920313090085983, 0.08642140030860901, 0.03288641571998596, 0.14423923194408417, 0.05952741950750351, 0.0646001473069191, 0.08534541726112366, 0.0445704460144043, 0.054796453565359116, 0.041703034192323685]\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 214\n",
      "Early stopping at epoch 187\n",
      "Early stopping at epoch 185\n",
      "Early stopping at epoch 232\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 228\n",
      "Early stopping at epoch 209\n",
      "Early stopping at epoch 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:38:02,257] Trial 28 finished with value: 0.12594905197620393 and parameters: {'lr': 0.028106081734476488, 'num_neuron': 9, 'num_layer': 2, 'batch_size': 17, 'weight_decay': 0.00011733032154342641}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 196\n",
      "Validation loss: [0.2577766180038452, 0.18800416588783264, 0.05858646333217621, 0.14986425638198853, 0.07573742419481277, 0.07545431703329086, 0.09569567441940308, 0.22525174915790558, 0.0894804447889328, 0.0436394065618515]\n",
      "Early stopping at epoch 439\n",
      "Early stopping at epoch 1230\n",
      "Early stopping at epoch 292\n",
      "Early stopping at epoch 312\n",
      "Early stopping at epoch 249\n",
      "Early stopping at epoch 381\n",
      "Early stopping at epoch 448\n",
      "Early stopping at epoch 386\n",
      "Early stopping at epoch 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:38:34,087] Trial 29 finished with value: 0.09709901288151741 and parameters: {'lr': 0.000904123563299114, 'num_neuron': 9, 'num_layer': 2, 'batch_size': 33, 'weight_decay': 0.0005740529284690341}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 564\n",
      "Validation loss: [0.06617432832717896, 0.18020929396152496, 0.20370331406593323, 0.10524361580610275, 0.07209272682666779, 0.05210287123918533, 0.06732115149497986, 0.07093379646539688, 0.07418312877416611, 0.07902590185403824]\n",
      "Early stopping at epoch 346\n",
      "Early stopping at epoch 243\n",
      "Early stopping at epoch 213\n",
      "Early stopping at epoch 222\n",
      "Early stopping at epoch 190\n",
      "Early stopping at epoch 193\n",
      "Early stopping at epoch 184\n",
      "Early stopping at epoch 185\n",
      "Early stopping at epoch 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:38:49,952] Trial 30 finished with value: 0.10073035396635532 and parameters: {'lr': 0.004931798253010885, 'num_neuron': 11, 'num_layer': 5, 'batch_size': 48, 'weight_decay': 0.0019398418176312191}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 198\n",
      "Validation loss: [0.048325393348932266, 0.24722513556480408, 0.06954903155565262, 0.11869698017835617, 0.1664307713508606, 0.06272917240858078, 0.10827723890542984, 0.07466917484998703, 0.05719508230686188, 0.05420555919408798]\n",
      "Early stopping at epoch 197\n",
      "Early stopping at epoch 196\n",
      "Early stopping at epoch 205\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 193\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:39:03,021] Trial 31 finished with value: 0.0721618089824915 and parameters: {'lr': 0.06751401957118125, 'num_neuron': 12, 'num_layer': 3, 'batch_size': 57, 'weight_decay': 0.005528877101114343}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 187\n",
      "Validation loss: [0.09934494644403458, 0.10596556961536407, 0.06773589551448822, 0.11244308203458786, 0.06357304751873016, 0.06259353458881378, 0.06467077881097794, 0.04014870151877403, 0.05669607222080231, 0.04844646155834198]\n",
      "Early stopping at epoch 194\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 186\n",
      "Early stopping at epoch 207\n",
      "Early stopping at epoch 184\n",
      "Early stopping at epoch 184\n",
      "Early stopping at epoch 212\n",
      "Early stopping at epoch 190\n",
      "Early stopping at epoch 206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:39:16,569] Trial 32 finished with value: 0.05989247150719166 and parameters: {'lr': 0.03865773102021936, 'num_neuron': 14, 'num_layer': 3, 'batch_size': 61, 'weight_decay': 0.008670683177197418}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 233\n",
      "Validation loss: [0.06915513426065445, 0.0926944836974144, 0.05974246934056282, 0.07076486200094223, 0.06308283656835556, 0.054118987172842026, 0.04649817571043968, 0.0457768514752388, 0.06137348711490631, 0.0357174277305603]\n",
      "Early stopping at epoch 190\n",
      "Early stopping at epoch 189\n",
      "Early stopping at epoch 189\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 190\n",
      "Early stopping at epoch 265\n",
      "Early stopping at epoch 199\n",
      "Early stopping at epoch 299\n",
      "Early stopping at epoch 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:39:31,354] Trial 33 finished with value: 0.07610781863331795 and parameters: {'lr': 0.017823473556851425, 'num_neuron': 15, 'num_layer': 4, 'batch_size': 60, 'weight_decay': 0.004577630870380299}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 197\n",
      "Validation loss: [0.06880684196949005, 0.14327357709407806, 0.026364680379629135, 0.12201782315969467, 0.061542801558971405, 0.04948228597640991, 0.07136986404657364, 0.051860399544239044, 0.1085638552904129, 0.05779605731368065]\n",
      "Early stopping at epoch 204\n",
      "Early stopping at epoch 354\n",
      "Early stopping at epoch 202\n",
      "Early stopping at epoch 184\n",
      "Early stopping at epoch 223\n",
      "Early stopping at epoch 223\n",
      "Early stopping at epoch 191\n",
      "Early stopping at epoch 199\n",
      "Early stopping at epoch 212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:39:44,549] Trial 34 finished with value: 0.0691367469727993 and parameters: {'lr': 0.04299046550321034, 'num_neuron': 14, 'num_layer': 2, 'batch_size': 62, 'weight_decay': 0.001008306352774215}. Best is trial 11 with value: 0.059244954586029054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 264\n",
      "Validation loss: [0.05724276602268219, 0.14826950430870056, 0.02604086697101593, 0.06254477053880692, 0.04531096667051315, 0.11154890805482864, 0.0953824371099472, 0.04428011551499367, 0.049040455371141434, 0.05170667916536331]\n",
      "Early stopping at epoch 326\n",
      "Early stopping at epoch 188\n",
      "Early stopping at epoch 244\n",
      "Early stopping at epoch 199\n",
      "Early stopping at epoch 261\n",
      "Early stopping at epoch 185\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 332\n",
      "Early stopping at epoch 205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:39:59,334] Trial 35 finished with value: 0.05658496543765068 and parameters: {'lr': 0.01076070745576319, 'num_neuron': 13, 'num_layer': 3, 'batch_size': 53, 'weight_decay': 0.009712546959747659}. Best is trial 35 with value: 0.05658496543765068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 200\n",
      "Validation loss: [0.06939304620027542, 0.09079958498477936, 0.03191123157739639, 0.06117204949259758, 0.06077929958701134, 0.056935131549835205, 0.0525105856359005, 0.04924936220049858, 0.05227411165833473, 0.0408252514898777]\n",
      "Early stopping at epoch 203\n",
      "Early stopping at epoch 213\n",
      "Early stopping at epoch 214\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 190\n",
      "Early stopping at epoch 195\n",
      "Early stopping at epoch 199\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:40:12,737] Trial 36 finished with value: 0.09824063684791326 and parameters: {'lr': 0.012229134189967628, 'num_neuron': 14, 'num_layer': 3, 'batch_size': 53, 'weight_decay': 0.0026209618357223665}. Best is trial 35 with value: 0.05658496543765068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 195\n",
      "Validation loss: [0.07487541437149048, 0.11095847934484482, 0.045339714735746384, 0.2367124855518341, 0.07139984518289566, 0.05834342911839485, 0.15480338037014008, 0.11524798721075058, 0.08601107448339462, 0.028714558109641075]\n",
      "Early stopping at epoch 238\n",
      "Early stopping at epoch 213\n",
      "Early stopping at epoch 256\n",
      "Early stopping at epoch 257\n",
      "Early stopping at epoch 227\n",
      "Early stopping at epoch 222\n",
      "Early stopping at epoch 262\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:40:34,217] Trial 37 finished with value: 0.06624789573252202 and parameters: {'lr': 0.024512897296221997, 'num_neuron': 13, 'num_layer': 4, 'batch_size': 39, 'weight_decay': 0.005440125766110247}. Best is trial 35 with value: 0.05658496543765068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 248\n",
      "Validation loss: [0.09740161895751953, 0.07040361315011978, 0.1053815707564354, 0.06285609304904938, 0.06571681797504425, 0.05921119078993797, 0.047908443957567215, 0.04863813519477844, 0.059993598610162735, 0.04496787488460541]\n",
      "Early stopping at epoch 198\n",
      "Early stopping at epoch 185\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 433\n",
      "Early stopping at epoch 221\n",
      "Early stopping at epoch 189\n",
      "Early stopping at epoch 288\n",
      "Early stopping at epoch 185\n",
      "Early stopping at epoch 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:40:51,595] Trial 38 finished with value: 0.0978355947881937 and parameters: {'lr': 0.0051299702302316985, 'num_neuron': 15, 'num_layer': 5, 'batch_size': 43, 'weight_decay': 0.0006066626334632825}. Best is trial 35 with value: 0.05658496543765068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 221\n",
      "Validation loss: [0.14956678450107574, 0.0869332030415535, 0.0723252072930336, 0.08707986772060394, 0.07888150960206985, 0.15583083033561707, 0.03903236612677574, 0.21579943597316742, 0.05050497129559517, 0.04240177199244499]\n",
      "Early stopping at epoch 270\n",
      "Early stopping at epoch 244\n",
      "Early stopping at epoch 251\n",
      "Early stopping at epoch 198\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 184\n",
      "Early stopping at epoch 266\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:41:05,199] Trial 39 finished with value: 0.09714563079178333 and parameters: {'lr': 0.009211874414458407, 'num_neuron': 13, 'num_layer': 3, 'batch_size': 62, 'weight_decay': 0.0015479729025715898}. Best is trial 35 with value: 0.05658496543765068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 203\n",
      "Validation loss: [0.11559043824672699, 0.06309828907251358, 0.04691571369767189, 0.24054133892059326, 0.0861084908246994, 0.11865132302045822, 0.06950675696134567, 0.12050855159759521, 0.08065788447856903, 0.029877521097660065]\n",
      "Early stopping at epoch 195\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 195\n",
      "Early stopping at epoch 213\n",
      "Early stopping at epoch 252\n",
      "Early stopping at epoch 207\n",
      "Early stopping at epoch 193\n",
      "Early stopping at epoch 227\n",
      "Early stopping at epoch 254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:41:22,824] Trial 40 finished with value: 0.0672055084258318 and parameters: {'lr': 0.03453802813724257, 'num_neuron': 14, 'num_layer': 3, 'batch_size': 34, 'weight_decay': 4.212067407748709e-05}. Best is trial 35 with value: 0.05658496543765068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 200\n",
      "Validation loss: [0.12256352603435516, 0.12503141164779663, 0.043544284999370575, 0.0694754347205162, 0.04784196615219116, 0.05088711529970169, 0.0611337311565876, 0.03950759023427963, 0.07012596726417542, 0.04194405674934387]\n",
      "Early stopping at epoch 199\n",
      "Early stopping at epoch 188\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 199\n",
      "Early stopping at epoch 205\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 247\n",
      "Early stopping at epoch 207\n",
      "Early stopping at epoch 245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:41:36,524] Trial 41 finished with value: 0.06053857058286667 and parameters: {'lr': 0.05926745438742744, 'num_neuron': 7, 'num_layer': 3, 'batch_size': 61, 'weight_decay': 0.009424593843108852}. Best is trial 35 with value: 0.05658496543765068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 187\n",
      "Validation loss: [0.06186562776565552, 0.12980353832244873, 0.03308815136551857, 0.07264402508735657, 0.06444495171308517, 0.05335758998990059, 0.04546566307544708, 0.04464796185493469, 0.05728429555892944, 0.04278390109539032]\n",
      "Early stopping at epoch 306\n",
      "Early stopping at epoch 228\n",
      "Early stopping at epoch 191\n",
      "Early stopping at epoch 185\n",
      "Early stopping at epoch 211\n",
      "Early stopping at epoch 195\n",
      "Early stopping at epoch 221\n",
      "Early stopping at epoch 218\n",
      "Early stopping at epoch 186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:41:56,256] Trial 42 finished with value: 0.08131113313138486 and parameters: {'lr': 0.060645297738081666, 'num_neuron': 5, 'num_layer': 3, 'batch_size': 27, 'weight_decay': 1.1048586702226373e-06}. Best is trial 35 with value: 0.05658496543765068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 206\n",
      "Validation loss: [0.05612222105264664, 0.12222237139940262, 0.10655630379915237, 0.09481233358383179, 0.07799963653087616, 0.0673205703496933, 0.07992581278085709, 0.08406747132539749, 0.06409270316362381, 0.05999190732836723]\n",
      "Early stopping at epoch 237\n",
      "Early stopping at epoch 217\n",
      "Early stopping at epoch 185\n",
      "Early stopping at epoch 190\n",
      "Early stopping at epoch 244\n",
      "Early stopping at epoch 185\n",
      "Early stopping at epoch 233\n",
      "Early stopping at epoch 187\n",
      "Early stopping at epoch 186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:42:09,758] Trial 43 finished with value: 0.0777124285697937 and parameters: {'lr': 0.02368105010923003, 'num_neuron': 7, 'num_layer': 3, 'batch_size': 62, 'weight_decay': 0.006029164209990602}. Best is trial 35 with value: 0.05658496543765068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 193\n",
      "Validation loss: [0.06872490793466568, 0.18634691834449768, 0.11437495797872543, 0.06573603302240372, 0.07740504294633865, 0.0635167732834816, 0.04121560603380203, 0.05297158658504486, 0.06818200647830963, 0.038650453090667725]\n",
      "Early stopping at epoch 191\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 211\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 354\n",
      "Early stopping at epoch 222\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:42:23,618] Trial 44 finished with value: 0.08448504023253918 and parameters: {'lr': 0.033932299081102624, 'num_neuron': 15, 'num_layer': 3, 'batch_size': 58, 'weight_decay': 0.003612106160645773}. Best is trial 35 with value: 0.05658496543765068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 189\n",
      "Validation loss: [0.08202178031206131, 0.10971969366073608, 0.03811274468898773, 0.1913270503282547, 0.05318475887179375, 0.0722259134054184, 0.06382545828819275, 0.12750595808029175, 0.06864995509386063, 0.03827708959579468]\n",
      "Early stopping at epoch 191\n",
      "Early stopping at epoch 213\n",
      "Early stopping at epoch 219\n",
      "Early stopping at epoch 193\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 206\n",
      "Early stopping at epoch 270\n",
      "Early stopping at epoch 228\n",
      "Early stopping at epoch 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:42:37,673] Trial 45 finished with value: 0.06250722259283066 and parameters: {'lr': 0.06671703822730227, 'num_neuron': 5, 'num_layer': 3, 'batch_size': 55, 'weight_decay': 0.009933295906572782}. Best is trial 35 with value: 0.05658496543765068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 197\n",
      "Validation loss: [0.0651242583990097, 0.12980273365974426, 0.04963189736008644, 0.07025665044784546, 0.07542312145233154, 0.050828855484724045, 0.04379493370652199, 0.040855444967746735, 0.05748218297958374, 0.04187214747071266]\n",
      "Early stopping at epoch 407\n",
      "Early stopping at epoch 185\n",
      "Early stopping at epoch 210\n",
      "Early stopping at epoch 275\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 199\n",
      "Early stopping at epoch 247\n",
      "Early stopping at epoch 238\n",
      "Early stopping at epoch 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:42:53,236] Trial 46 finished with value: 0.06571733802556992 and parameters: {'lr': 0.015539108023791041, 'num_neuron': 6, 'num_layer': 4, 'batch_size': 47, 'weight_decay': 0.007341491460408784}. Best is trial 35 with value: 0.05658496543765068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 201\n",
      "Validation loss: [0.052469462156295776, 0.13702653348445892, 0.043219681829214096, 0.07081792503595352, 0.06465719640254974, 0.07455647736787796, 0.0474422425031662, 0.055456407368183136, 0.0630393773317337, 0.0484880767762661]\n",
      "Early stopping at epoch 317\n",
      "Early stopping at epoch 343\n",
      "Early stopping at epoch 393\n",
      "Early stopping at epoch 232\n",
      "Early stopping at epoch 751\n",
      "Early stopping at epoch 821\n",
      "Early stopping at epoch 881\n",
      "Early stopping at epoch 654\n",
      "Early stopping at epoch 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:43:22,122] Trial 47 finished with value: 0.0872262503951788 and parameters: {'lr': 0.0010914231465295745, 'num_neuron': 12, 'num_layer': 3, 'batch_size': 64, 'weight_decay': 0.0037474148763992454}. Best is trial 35 with value: 0.05658496543765068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 481\n",
      "Validation loss: [0.12162812054157257, 0.08684840798377991, 0.053538255393505096, 0.07898545265197754, 0.0753457099199295, 0.052131764590740204, 0.072417713701725, 0.160422220826149, 0.052046339958906174, 0.11889851838350296]\n",
      "Early stopping at epoch 278\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 212\n",
      "Early stopping at epoch 185\n",
      "Early stopping at epoch 185\n",
      "Early stopping at epoch 227\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 285\n",
      "Early stopping at epoch 221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:43:37,308] Trial 48 finished with value: 0.05936257503926754 and parameters: {'lr': 0.0074171409204860095, 'num_neuron': 13, 'num_layer': 3, 'batch_size': 62, 'weight_decay': 0.006562233964456998}. Best is trial 35 with value: 0.05658496543765068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 281\n",
      "Validation loss: [0.05695060268044472, 0.0933312326669693, 0.04104078933596611, 0.07012400776147842, 0.08332748711109161, 0.06240463629364967, 0.05008235573768616, 0.05766924470663071, 0.049309052526950836, 0.02938634157180786]\n",
      "Early stopping at epoch 184\n",
      "Early stopping at epoch 194\n",
      "Early stopping at epoch 194\n",
      "Early stopping at epoch 259\n",
      "Early stopping at epoch 229\n",
      "Early stopping at epoch 315\n",
      "Early stopping at epoch 187\n",
      "Early stopping at epoch 377\n",
      "Early stopping at epoch 427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-30 16:43:56,343] Trial 49 finished with value: 0.1244136482477188 and parameters: {'lr': 0.0024345610396225006, 'num_neuron': 13, 'num_layer': 4, 'batch_size': 50, 'weight_decay': 2.614378217770161e-05}. Best is trial 35 with value: 0.05658496543765068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 456\n",
      "Validation loss: [0.08257288485765457, 0.2314341515302658, 0.12075769156217575, 0.08171475678682327, 0.07590070366859436, 0.09860905259847641, 0.1868748664855957, 0.11932073533535004, 0.047991156578063965, 0.19896048307418823]\n",
      "Best hyperparameters: {'lr': 0.01076070745576319, 'num_neuron': 13, 'num_layer': 3, 'batch_size': 53, 'weight_decay': 0.009712546959747659}\n"
     ]
    }
   ],
   "source": [
    "best_model_path = 'Best_network/best_e2e_model_V2.pth'  # File to save the best model\n",
    "best_val_loss = float('inf')\n",
    "b_weight = [5e-4,30,5]\n",
    "# Hyperparameters to optimize: lr, # of neurons, # of layers\n",
    "def objective(trial):\n",
    "    global best_val_loss\n",
    "\n",
    "    val_loss_CV = []\n",
    "    model_state_dict = {}\n",
    "    # Hyperparameter search space\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-1, log=True)\n",
    "    num_neuron = trial.suggest_int('num_neuron', 5, 15)\n",
    "    num_layer = trial.suggest_int('num_layer', 2, 5)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
    "\n",
    "    hidden_sizes = [num_neuron] * num_layer  # Mapping\n",
    "    num_epochs = 3000\n",
    "    warmup_epochs = 150\n",
    "    \n",
    "    for fold in range(10):\n",
    "        # Initialize the model, loss function, and optimizer\n",
    "        model = network(input_size,hidden_sizes,output_size)\n",
    "        criterion = end_to_end_loss_NN_new\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "        early_stopping = EarlyStopping(patience=30, min_delta=5e-6)\n",
    "\n",
    "        # Load dataset for the current fold\n",
    "        train_dataset = train_dataset_CV[fold]\n",
    "        val_dataset = val_dataset_CV[fold]\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            for batch in train_loader:\n",
    "                inputs, labels = batch\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels,a, b_weight)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_loader:\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets, a, b_weight)\n",
    "                    val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # Check early stopping condition after warmup\n",
    "            if epoch > warmup_epochs:\n",
    "                early_stopping(val_loss)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        val_loss_CV.append(val_loss)\n",
    "        model_state_dict[fold] = model.state_dict()\n",
    "\n",
    "    val_loss_overall = np.mean(val_loss_CV)\n",
    "    print(f\"Validation loss: {val_loss_CV}\")\n",
    "\n",
    "    # Check if the current validation loss is the best\n",
    "    if val_loss_overall < best_val_loss:\n",
    "        best_val_loss = val_loss_overall\n",
    "        # Save the best model\n",
    "        torch.save({'model_state':model_state_dict,\n",
    "                    'lr':lr,\n",
    "                    'num_neuron':num_neuron,\n",
    "                    'num_layer':num_layer,\n",
    "                    'batch_size':batch_size,\n",
    "                    'weight_decay':weight_decay}, best_model_path)\n",
    "\n",
    "    return val_loss_overall\n",
    "\n",
    "\n",
    "# Create an Optuna study\n",
    "sampler = optuna.samplers.TPESampler(seed=seed_)  # Make the sampler deterministic\n",
    "study = optuna.create_study(sampler=sampler, direction='minimize')\n",
    "\n",
    "# Run the optimization\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_dict = torch.load(best_model_path)\n",
    "hidden_sizes = [best_model_dict['num_neuron']]*best_model_dict['num_layer']\n",
    "\n",
    "# Test features as tensor\n",
    "X_train_PCA_tensor = torch.tensor(X_train_PCA,dtype = torch.float32)\n",
    "X_test_in_PCA_tensor = torch.tensor(X_test_in_PCA,dtype=torch.float32)\n",
    "X_test_out_PCA_tensor = torch.tensor(X_test_out_PCA,dtype=torch.float32)\n",
    "\n",
    "b_train_pred = []\n",
    "b_test_in_pred = []\n",
    "b_test_out_pred = []\n",
    "\n",
    "Q_train_pred = []\n",
    "Q_test_in_pred = []\n",
    "Q_test_out_pred = []\n",
    "for fold in range(10):\n",
    "    # Load the model for the current fold\n",
    "    model = network(input_size,hidden_sizes,output_size)\n",
    "    model.load_state_dict(best_model_dict['model_state'][fold])\n",
    "\n",
    "    # Evaluate the model with the completed training set and test sets\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        b_train_pred_fold = model(X_train_PCA_tensor).numpy()\n",
    "        b_test_in_pred_fold = model(X_test_in_PCA_tensor).numpy()\n",
    "        b_test_out_pred_fold = model(X_test_out_PCA_tensor).numpy()\n",
    "\n",
    "    Q_train_pred_fold = []\n",
    "    for i in range(num_training_cells):\n",
    "        b = b_train_pred_fold[i]\n",
    "        Q_train_pred_fold.append(np.clip(empirical_model(a,*b,N_train[i],b_weight),0,1))\n",
    "    \n",
    "    Q_test_in_pred_fold = []\n",
    "    for i in range(num_test_in_cells):\n",
    "        b = b_test_in_pred_fold[i]\n",
    "        Q_test_in_pred_fold.append(np.clip(empirical_model(a,*b,N_test_in[i],b_weight),0,1))\n",
    "\n",
    "    Q_test_out_pred_fold = []\n",
    "    for i in range(num_test_out_cells):\n",
    "        b = b_test_out_pred_fold[i]\n",
    "        Q_test_out_pred_fold.append(np.clip(empirical_model(a,*b,N_test_out[i],b_weight),0,1))\n",
    "    \n",
    "    # Save the results from the current fold\n",
    "    b_train_pred.append(np.array(b_train_pred_fold))\n",
    "    b_test_in_pred.append(np.array(b_test_in_pred_fold))\n",
    "    b_test_out_pred.append(np.array(b_test_out_pred_fold))\n",
    "\n",
    "    Q_train_pred.append(np.array(Q_train_pred_fold))\n",
    "    Q_test_in_pred.append(np.array(Q_test_in_pred_fold))\n",
    "    Q_test_out_pred.append(np.array(Q_test_out_pred_fold))\n",
    "\n",
    "\n",
    "# Write the results to files\n",
    "with open('Empirical_parameter_results/E2E_NN_V2/b_train_pred.pkl','wb') as f:\n",
    "    pickle.dump(b_train_pred,f)\n",
    "\n",
    "with open('Empirical_parameter_results/E2E_NN_V2/b_test_in_pred.pkl','wb') as f:\n",
    "    pickle.dump(b_test_in_pred,f)\n",
    "\n",
    "with open('Empirical_parameter_results/E2E_NN_V2/b_test_out_pred.pkl','wb') as f:\n",
    "    pickle.dump(b_test_out_pred,f)\n",
    "\n",
    "with open('Empirical_parameter_results/E2E_NN_V2/Q_train_pred.pkl','wb') as f:\n",
    "    pickle.dump(Q_train_pred,f)\n",
    "\n",
    "with open('Empirical_parameter_results/E2E_NN_V2/Q_test_in_pred.pkl','wb') as f:\n",
    "    pickle.dump(Q_test_in_pred,f)\n",
    "\n",
    "with open('Empirical_parameter_results/E2E_NN_V2/Q_test_out_pred.pkl','wb') as f:\n",
    "    pickle.dump(Q_test_out_pred,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE training: 1.61\n",
      "Mean MAE test in: 1.96\n",
      "Mean MAE test out: 5.92\n",
      "Mean RMSE training: 1.93\n",
      "Mean RMSE test in: 2.38\n",
      "Mean RMSE test out: 7.62\n"
     ]
    }
   ],
   "source": [
    "MAE_training = []\n",
    "MAE_test_in = []\n",
    "MAE_test_out = []\n",
    "\n",
    "RMSE_training = []\n",
    "RMSE_test_in = []\n",
    "RMSE_test_out = []\n",
    "\n",
    "for fold in range(10):\n",
    "    MAE_training_fold = []\n",
    "    MAE_test_in_fold = []\n",
    "    MAE_test_out_fold = []\n",
    "\n",
    "    RMSE_training_fold = []\n",
    "    RMSE_test_in_fold = []\n",
    "    RMSE_test_out_fold = []\n",
    "\n",
    "    for i in range(num_training_cells):\n",
    "        MAE_training_fold.append(mean_absolute_error(Q_train[i],Q_train_pred[fold][i]))\n",
    "        RMSE_training_fold.append(root_mean_squared_error(Q_train[i],Q_train_pred[fold][i]))\n",
    "\n",
    "    for i in range(num_test_in_cells):\n",
    "        MAE_test_in_fold.append(mean_absolute_error(Q_test_in[i],Q_test_in_pred[fold][i]))\n",
    "        RMSE_test_in_fold.append(root_mean_squared_error(Q_test_in[i],Q_test_in_pred[fold][i]))\n",
    "\n",
    "    for i in range(num_test_out_cells):\n",
    "        MAE_test_out_fold.append(mean_absolute_error(Q_test_out[i],Q_test_out_pred[fold][i]))\n",
    "        RMSE_test_out_fold.append(root_mean_squared_error(Q_test_out[i],Q_test_out_pred[fold][i]))\n",
    "\n",
    "    MAE_training.append(np.mean(MAE_training_fold)*100)\n",
    "    MAE_test_in.append(np.mean(MAE_test_in_fold)*100)\n",
    "    MAE_test_out.append(np.mean(MAE_test_out_fold)*100)\n",
    "\n",
    "    RMSE_training.append(np.mean(RMSE_training_fold)*100)\n",
    "    RMSE_test_in.append(np.mean(RMSE_test_in_fold)*100)\n",
    "    RMSE_test_out.append(np.mean(RMSE_test_out_fold)*100)\n",
    "\n",
    "result_dict = {'MAE_training':MAE_training,\n",
    "                'MAE_test_in':MAE_test_in,\n",
    "                'MAE_test_out':MAE_test_out,\n",
    "                'RMSE_training':RMSE_training,\n",
    "                'RMSE_test_in':RMSE_test_in,\n",
    "                'RMSE_test_out':RMSE_test_out}\n",
    "\n",
    "with open('Empirical_parameter_results/E2E_NN_V2/result_dict.pkl','wb') as f:\n",
    "    pickle.dump(result_dict,f)\n",
    "\n",
    "mean_MAE_training = np.mean(MAE_training)\n",
    "mean_MAE_test_in = np.mean(MAE_test_in)\n",
    "mean_MAE_test_out = np.mean(MAE_test_out)\n",
    "\n",
    "mean_RMSE_training = np.mean(RMSE_training)\n",
    "mean_RMSE_test_in = np.mean(RMSE_test_in)\n",
    "mean_RMSE_test_out = np.mean(RMSE_test_out)\n",
    "\n",
    "print(f\"Mean MAE training: {mean_MAE_training:.2f}\")\n",
    "print(f\"Mean MAE test in: {mean_MAE_test_in:.2f}\")\n",
    "print(f\"Mean MAE test out: {mean_MAE_test_out:.2f}\")\n",
    "\n",
    "print(f\"Mean RMSE training: {mean_RMSE_training:.2f}\")\n",
    "print(f\"Mean RMSE test in: {mean_RMSE_test_in:.2f}\")\n",
    "print(f\"Mean RMSE test out: {mean_RMSE_test_out:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE training: [1.626228323840059, 1.6860557973806927, 1.7895224094858453, 1.5509387892372928, 1.6322002107092732, 1.6425266636706823, 1.5897918335482364, 1.446117432767043, 1.5316686630140877, 1.5721812136068425]\n",
      "MAE test in: [1.9755471885980376, 1.9333037101736168, 1.9386984393359827, 1.8146269132034458, 1.972943259194214, 2.0147058095852413, 1.997685948220411, 2.129031755860818, 1.8731557441158513, 1.943490135410681]\n",
      "MAE test out: [5.813316707104044, 6.5058748542168034, 4.950125728430968, 4.980477325752973, 6.30243215889435, 4.80039705927338, 7.14141647932349, 7.300519370957207, 5.927727415509792, 5.523207241558596]\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAE training: {MAE_training}\")\n",
    "print(f\"MAE test in: {MAE_test_in}\")\n",
    "print(f\"MAE test out: {MAE_test_out}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
